{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f12bba58-ee1a-4465-b723-5235622f0ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from NeuralProcessClasses_Proteins import *\n",
    "from architecture_classes import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3db1fcd-7707-4b05-bdf1-d980908f3f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa = pd.read_csv('SH3_Full_Dataset_8_9_22.csv')\n",
    "msa['Type'].unique()\n",
    "naturals_msa = msa[msa['Type']=='Naturals']\n",
    "seqs = np.asarray([list(seq) for seq in naturals_msa['Sequences']])\n",
    "norm_re = np.asarray([re for re in naturals_msa['Norm_RE']])\n",
    "\n",
    "default_aa_keys='-GALMFWKQESPVICYHRNDT'\n",
    "def fasta_to_df(fasta_file, aa_keys = default_aa_keys):\n",
    "    \"\"\"\n",
    "    creates one hot encoding of a fasta file using biopython's alignio.read process. \n",
    "    fasta_file : filepath leading to msa file in fasta format at hand\n",
    "    \"\"\"\n",
    "    column_names = []\n",
    "    column_names.extend(aa_keys)\n",
    "    msa=AlignIO.read(fasta_file, \"fasta\")\n",
    "    num_columns = len(msa[0].seq)\n",
    "    column_names = column_names*num_columns\n",
    "    column_names.append('sequence')\n",
    "    column_names.append('id')\n",
    "    init = np.zeros((len(msa), len(column_names)))\n",
    "    df = pd.DataFrame(init, columns = column_names)\n",
    "    df.sequence = df.sequence.astype(str)\n",
    "    df.id=df.id.astype(str)\n",
    "    \n",
    "    for row_num, alignment in tqdm(enumerate(msa)):\n",
    "        sequence = str(alignment.seq)\n",
    "        for index, char in enumerate(sequence):\n",
    "            place = aa_keys.find(char)\n",
    "            df.iloc[row_num, index*len(aa_keys) + place] = 1\n",
    "        \n",
    "        df.iloc[row_num,-2]=str(alignment.seq)\n",
    "        df.iloc[row_num,-1]=str(alignment.id)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b21f2cf-79ef-4424-b94c-d9924b2e04d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_frequency_matrix(df, aa_keys = default_aa_keys):\n",
    "    \"\"\"takes one hot encoded msa and returns the frequency of each amino acid at each site\n",
    "    df : pandas dataframe whose columns are the one hot encoding of an msa\n",
    "    \"\"\"\n",
    "    num_columns=len(df['sequence'][0])\n",
    "    \n",
    "    frequency_matrix = np.zeros( (len(aa_keys) , num_columns) )\n",
    "    print('calcing sum')\n",
    "    freq=df.sum()\n",
    "    print('sum calced')\n",
    "    \n",
    "    num_entries=len(df)\n",
    "    len_aa_keys = len(aa_keys)\n",
    "    \n",
    "    for i in tqdm(range(len(aa_keys))):\n",
    "        for j in range(num_columns):\n",
    "            frequency_matrix[i, j] = freq[ i + len_aa_keys * j] / num_entries\n",
    "    \n",
    "    return frequency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e50738df-3847-4dce-b69a-f086ef092ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11608it [01:01, 187.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calcing sum\n",
      "sum calced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 21/21 [00:00<00:00, 23252.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 17, 44]\n"
     ]
    }
   ],
   "source": [
    "from Bio import AlignIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from tqdm import tqdm\n",
    "vae_alignment = []\n",
    "phenotypes = []\n",
    "\n",
    "vae_data = msa[msa['Type']=='VAE'].reset_index()\n",
    "\n",
    "for r in range(len(vae_data)):\n",
    "    alignment = vae_data.loc[r]\n",
    "    if len(alignment['Sequences'])==62:\n",
    "        record = SeqRecord(seq = Seq(alignment['Sequences']), id = alignment['Header'])\n",
    "    \n",
    "    vae_alignment.append(record)\n",
    "    phenotypes.append(alignment['Norm_RE'])\n",
    "\n",
    "vae_alignment = AlignIO.MultipleSeqAlignment(vae_alignment)\n",
    "\n",
    "AlignIO.write(vae_alignment, 'vae_alignment.fasta', 'fasta')\n",
    "\n",
    "vae_df = fasta_to_df('vae_alignment.fasta')\n",
    "\n",
    "freq_matrix = create_frequency_matrix(vae_df)\n",
    "\n",
    "trim_positions = []\n",
    "\n",
    "for i in range(freq_matrix.shape[1]):\n",
    "    if 1 in freq_matrix[:,i]:\n",
    "        trim_positions.append(i)\n",
    "\n",
    "print(trim_positions)\n",
    "\n",
    "\n",
    "vae_alignment_trimmed = []\n",
    "\n",
    "\n",
    "for alignment in vae_alignment:\n",
    "    new_seq = ''\n",
    "    for i in range(62):\n",
    "        if i not in trim_positions:\n",
    "            new_seq+=alignment.seq[i]\n",
    "    re_alignment = SeqRecord(seq=Seq(new_seq), id = alignment.id)\n",
    "    vae_alignment_trimmed.append(re_alignment)\n",
    "\n",
    "vae_alignment_trimmed = AlignIO.MultipleSeqAlignment(vae_alignment_trimmed)\n",
    "\n",
    "AlignIO.write(vae_alignment_trimmed, 'vae_alignment_trimmed.fasta', 'fasta')\n",
    "\n",
    "test_seqs = np.asarray([list(str(alignment.seq)) for alignment in vae_alignment_trimmed])\n",
    "\n",
    "phenotypes = np.asarray(phenotypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c412150d-be7e-438d-a386-16c815e2e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNorm(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        normalized_shape,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.layer_norm = torch.nn.LayerNorm(normalized_shape)\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        sub_layer_x\n",
    "    ):\n",
    "        add = x + sub_layer_x\n",
    "        return self.layer_norm(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e518096f-e882-4361-a68b-38141628b0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentiveNeuralProcess_Deterministic(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_dim, \n",
    "        y_dim,\n",
    "        projected_dim,\n",
    "        d_hidden, \n",
    "        d_model,\n",
    "        heads,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.linear_1 = torch.nn.Linear(x_dim + y_dim, projected_dim)\n",
    "        self.activation = torch.nn.SELU()\n",
    "\n",
    "        self.self_mha_1 = MultiHeadedAttention(heads, projected_dim, projected_dim, projected_dim, d_hidden, projected_dim)\n",
    "        self.addnorm_1 = AddNorm(normalized_shape= projected_dim)\n",
    "        self.dropout_1 = torch.nn.Dropout(0.1)\n",
    "\n",
    "        self.self_mha_2 = MultiHeadedAttention(heads, projected_dim, projected_dim, projected_dim, d_hidden, projected_dim)\n",
    "        self.addnorm_2 = AddNorm(normalized_shape=projected_dim)\n",
    "        self.dropout_2 = torch.nn.Dropout(0.1)\n",
    "\n",
    "        self.context_projection = torch.nn.Linear(x_dim, projected_dim)\n",
    "        self.target_projection = torch.nn.Linear(x_dim, projected_dim)\n",
    "        \n",
    "        self.cross_mha = MultiHeadedAttention(heads, projected_dim, projected_dim, projected_dim, d_hidden, projected_dim)\n",
    "\n",
    "        self.linear_2 = torch.nn.Linear(projected_dim + x_dim, projected_dim)\n",
    "        self.linear_3 = torch.nn.Linear(projected_dim + x_dim, projected_dim)\n",
    "        self.linear_4 = torch.nn.Linear(projected_dim + x_dim, projected_dim)\n",
    "        self.linear_5 = torch.nn.Linear(projected_dim + x_dim, y_dim)\n",
    "\n",
    "    def cross_entropy(self, x, y):\n",
    "        return torch.sum(-y * torch.log(x + 1e-6) - (1.-y)*torch.log(1. - x + 1e-6))\n",
    "\n",
    "    def forward(self, context_x, context_y, target_x, target_y = None):\n",
    "        context = torch.concat([context_x, context_y], dim=-1)\n",
    "        x_1 = self.activation(self.linear_1(context))\n",
    "\n",
    "        x_2, _ = self.self_mha_1(x_1, x_1, x_1)\n",
    "        x_2    = self.addnorm_1(x_2, x_1)\n",
    "        x_2    = self.dropout_1(x_2)\n",
    "\n",
    "        x_3, _ = self.self_mha_2(x_2, x_2, x_2)\n",
    "        x_3    = self.addnorm_2(x_3, x_2)\n",
    "        x_3    = self.dropout_2(x_2)\n",
    "\n",
    "        projected_context = self.context_projection(context_x)\n",
    "        projected_target  = self.target_projection(target_x)\n",
    "        \n",
    "        cross_attended,_ = self.cross_mha(projected_target, projected_context, x_3)\n",
    "        \n",
    "        yhat = torch.concat([cross_attended, x_target], dim=-1)\n",
    "        yhat = self.activation(self.linear_2(yhat))\n",
    "        \n",
    "        yhat = torch.concat([yhat, x_target], dim=-1)\n",
    "        yhat = self.activation(self.linear_3(yhat))\n",
    "        \n",
    "        yhat = torch.concat([yhat, x_target], dim=-1)\n",
    "        yhat = self.activation(self.linear_4(yhat))\n",
    "\n",
    "        yhat = torch.concat([yhat, x_target], dim=-1)\n",
    "        yhat = self.linear_5(yhat)\n",
    "        \n",
    "        yhat = torch.nn.Softmax(dim=-1)(yhat)\n",
    "\n",
    "        if target_y is not None:\n",
    "            cross_entropy = self.cross_entropy(yhat, target_y)\n",
    "            return yhat, cross_entropy\n",
    "        else:\n",
    "            return yhat, 0\n",
    "                                     \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fce7f86a-c0f8-480c-babc-fdddab86ef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANP_det = AttentiveNeuralProcess_Deterministic(\n",
    "    1, 21, 128, 128, 128, 8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ad5e1d8-3073-4980-8db0-4095b18d0939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttentiveNeuralProcess_Deterministic(\n",
       "  (linear_1): Linear(in_features=22, out_features=128, bias=True)\n",
       "  (activation): SELU()\n",
       "  (self_mha_1): MultiHeadedAttention(\n",
       "    (attention): DotProductAttention()\n",
       "    (W_q): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_k): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_v): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_o): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  )\n",
       "  (addnorm_1): AddNorm(\n",
       "    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "  (self_mha_2): MultiHeadedAttention(\n",
       "    (attention): DotProductAttention()\n",
       "    (W_q): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_k): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_v): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_o): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  )\n",
       "  (addnorm_2): AddNorm(\n",
       "    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "  (context_projection): Linear(in_features=1, out_features=128, bias=True)\n",
       "  (target_projection): Linear(in_features=1, out_features=128, bias=True)\n",
       "  (cross_mha): MultiHeadedAttention(\n",
       "    (attention): DotProductAttention()\n",
       "    (W_q): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_k): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_v): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_o): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  )\n",
       "  (linear_2): Linear(in_features=129, out_features=128, bias=True)\n",
       "  (linear_3): Linear(in_features=129, out_features=128, bias=True)\n",
       "  (linear_4): Linear(in_features=129, out_features=128, bias=True)\n",
       "  (linear_5): Linear(in_features=129, out_features=21, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANP_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe663393-e00f-4b74-961a-7f6ee0e76c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins = ProteinDataset(data=seqs)\n",
    "min_context = int(0.1 * seqs.shape[1])\n",
    "max_context = int(0.9 * seqs.shape[1])\n",
    "len_aa = seqs.shape[1]\n",
    "loader = torch.utils.data.DataLoader(proteins, batch_size=32, shuffle=True)\n",
    "\n",
    "for batch in loader:\n",
    "    break\n",
    "(((x_context, y_context), x_target), y_target) = context_target_splitter(batch, min_context, max_context, len_aa, 1, 21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f64963f5-03f5-414b-a235-5a630709af01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[3.5835e-04, 2.6647e-04, 7.5835e-03,  ..., 2.0244e-03,\n",
       "           7.0126e-03, 2.3090e-02],\n",
       "          [1.7431e-04, 1.2880e-04, 5.1384e-03,  ..., 1.1936e-03,\n",
       "           4.8473e-03, 1.8830e-02],\n",
       "          [1.3055e-04, 9.6441e-05, 4.3880e-03,  ..., 9.6454e-04,\n",
       "           4.1777e-03, 1.7291e-02],\n",
       "          ...,\n",
       "          [1.1295e-04, 8.3479e-05, 4.0532e-03,  ..., 8.6688e-04,\n",
       "           3.8779e-03, 1.6559e-02],\n",
       "          [3.4965e-03, 2.7442e-03, 2.5257e-02,  ..., 1.0212e-02,\n",
       "           2.0575e-02, 4.0891e-02],\n",
       "          [1.6201e-02, 1.4010e-02, 5.0745e-02,  ..., 2.6948e-02,\n",
       "           3.5486e-02, 5.1035e-02]],\n",
       " \n",
       "         [[3.4747e-03, 2.7337e-03, 2.5280e-02,  ..., 1.0340e-02,\n",
       "           2.0554e-02, 4.2116e-02],\n",
       "          [7.9860e-03, 6.5923e-03, 3.7769e-02,  ..., 1.7812e-02,\n",
       "           2.8404e-02, 4.8797e-02],\n",
       "          [1.4951e-03, 1.1429e-03, 1.6387e-02,  ..., 5.7728e-03,\n",
       "           1.4131e-02, 3.4720e-02],\n",
       "          ...,\n",
       "          [9.7647e-04, 7.3865e-04, 1.3092e-02,  ..., 4.2648e-03,\n",
       "           1.1562e-02, 3.1114e-02],\n",
       "          [2.6293e-03, 2.0426e-03, 2.1927e-02,  ..., 8.5520e-03,\n",
       "           1.8238e-02, 3.9717e-02],\n",
       "          [7.3345e-05, 5.4180e-05, 3.2278e-03,  ..., 6.4334e-04,\n",
       "           3.1076e-03, 1.4818e-02]],\n",
       " \n",
       "         [[7.9754e-03, 6.5410e-03, 3.8417e-02,  ..., 1.8171e-02,\n",
       "           2.8889e-02, 4.8519e-02],\n",
       "          [3.4609e-03, 2.6847e-03, 2.5499e-02,  ..., 1.0492e-02,\n",
       "           2.0783e-02, 4.2022e-02],\n",
       "          [3.5104e-05, 2.6017e-05, 2.1648e-03,  ..., 3.7606e-04,\n",
       "           2.1522e-03, 1.1818e-02],\n",
       "          ...,\n",
       "          [8.4113e-04, 6.2491e-04, 1.2251e-02,  ..., 3.8626e-03,\n",
       "           1.0839e-02, 2.9859e-02],\n",
       "          [3.9772e-03, 3.1094e-03, 2.7365e-02,  ..., 1.1531e-02,\n",
       "           2.2038e-02, 4.3210e-02],\n",
       "          [6.9413e-03, 5.6355e-03, 3.6022e-02,  ..., 1.6647e-02,\n",
       "           2.7432e-02, 4.7544e-02]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[4.0823e-03, 3.1079e-03, 2.7464e-02,  ..., 1.1414e-02,\n",
       "           2.1847e-02, 4.3789e-02],\n",
       "          [4.2382e-04, 3.0489e-04, 8.3770e-03,  ..., 2.3004e-03,\n",
       "           7.6113e-03, 2.5141e-02],\n",
       "          [3.1030e-05, 2.2983e-05, 2.0096e-03,  ..., 3.4118e-04,\n",
       "           2.0159e-03, 1.1505e-02],\n",
       "          ...,\n",
       "          [1.5498e-04, 1.1072e-04, 4.8457e-03,  ..., 1.1014e-03,\n",
       "           4.5609e-03, 1.8827e-02],\n",
       "          [1.9915e-05, 1.5014e-05, 1.5813e-03,  ..., 2.4777e-04,\n",
       "           1.6137e-03, 1.0025e-02],\n",
       "          [2.3893e-04, 1.7068e-04, 6.1388e-03,  ..., 1.5125e-03,\n",
       "           5.6880e-03, 2.1380e-02]],\n",
       " \n",
       "         [[2.6189e-03, 2.0097e-03, 2.1521e-02,  ..., 8.7103e-03,\n",
       "           1.8167e-02, 3.8890e-02],\n",
       "          [6.3701e-05, 4.6881e-05, 2.8970e-03,  ..., 5.8807e-04,\n",
       "           2.8627e-03, 1.4203e-02],\n",
       "          [1.9770e-03, 1.5045e-03, 1.8602e-02,  ..., 7.1550e-03,\n",
       "           1.5962e-02, 3.6483e-02],\n",
       "          ...,\n",
       "          [1.3630e-02, 1.1779e-02, 4.7032e-02,  ..., 2.5871e-02,\n",
       "           3.5250e-02, 5.0827e-02],\n",
       "          [5.2450e-03, 4.1740e-03, 3.0576e-02,  ..., 1.4013e-02,\n",
       "           2.4623e-02, 4.4765e-02],\n",
       "          [7.3357e-04, 5.4758e-04, 1.0983e-02,  ..., 3.5261e-03,\n",
       "           9.9494e-03, 2.8478e-02]],\n",
       " \n",
       "         [[7.3646e-05, 5.3864e-05, 3.2118e-03,  ..., 6.3229e-04,\n",
       "           3.1533e-03, 1.4909e-02],\n",
       "          [2.6355e-05, 1.9835e-05, 1.8339e-03,  ..., 2.9983e-04,\n",
       "           1.8757e-03, 1.0864e-02],\n",
       "          [6.1184e-03, 4.8921e-03, 3.3682e-02,  ..., 1.4936e-02,\n",
       "           2.5963e-02, 4.5998e-02],\n",
       "          ...,\n",
       "          [8.5181e-05, 6.2176e-05, 3.4816e-03,  ..., 7.0364e-04,\n",
       "           3.3970e-03, 1.5594e-02],\n",
       "          [1.5019e-03, 1.1316e-03, 1.6462e-02,  ..., 5.7058e-03,\n",
       "           1.4239e-02, 3.4714e-02],\n",
       "          [2.6457e-03, 2.0246e-03, 2.2088e-02,  ..., 8.4852e-03,\n",
       "           1.8387e-02, 3.9535e-02]]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor(10221.3477, grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANP_det(x_context, y_context, x_target, y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "725298f2-5844-45a0-84f5-0a0a5d9e3278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, step_num, warmup_step=4000):\n",
    "    lr = 0.001 * warmup_step**0.5 * min(step_num * warmup_step**-1.5, step_num**-0.5)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95ece645-791d-4f8c-9867-549010b2e569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 0 is 3.8505323911975067\n",
      "validation loss at epoch 1 is 3.701777262273781\n",
      "validation loss at epoch 2 is 3.680813300582992\n",
      "validation loss at epoch 3 is 3.643248987698614\n",
      "validation loss at epoch 4 is 3.6416000966695234\n",
      "validation loss at epoch 5 is 3.5897274396312833\n",
      "validation loss at epoch 6 is 3.562509667636799\n",
      "validation loss at epoch 7 is 3.5311540430011465\n",
      "validation loss at epoch 8 is 3.5015016741666236\n",
      "validation loss at epoch 9 is 3.453404699134245\n",
      "validation loss at epoch 10 is 3.49460342817709\n",
      "validation loss at epoch 11 is 3.42166330228153\n",
      "validation loss at epoch 12 is 3.4117346278814233\n",
      "validation loss at epoch 13 is 3.372812533908024\n",
      "validation loss at epoch 14 is 3.315049077772471\n",
      "validation loss at epoch 15 is 3.281330435308532\n",
      "validation loss at epoch 16 is 3.2751466547706634\n",
      "validation loss at epoch 17 is 3.2154891567272332\n",
      "validation loss at epoch 18 is 3.2729680870396676\n",
      "validation loss at epoch 19 is 3.1846249895452634\n",
      "validation loss at epoch 20 is 3.264169806062985\n",
      "validation loss at epoch 21 is 3.2064745089057243\n",
      "validation loss at epoch 22 is 3.1122867218082813\n",
      "validation loss at epoch 23 is 3.104601966510257\n",
      "validation loss at epoch 24 is 3.108940395522813\n",
      "validation loss at epoch 25 is 3.118468719964734\n",
      "validation loss at epoch 26 is 3.07019016019143\n",
      "validation loss at epoch 27 is 3.0598972440288112\n",
      "validation loss at epoch 28 is 3.059526035293821\n",
      "validation loss at epoch 29 is 3.00928075807984\n",
      "validation loss at epoch 30 is 3.048721773865682\n",
      "validation loss at epoch 31 is 3.0160773684033293\n",
      "validation loss at epoch 32 is 2.9882429017073626\n",
      "validation loss at epoch 33 is 2.99022632255724\n",
      "validation loss at epoch 34 is 2.9797232875096094\n",
      "validation loss at epoch 35 is 2.9317528284054584\n",
      "validation loss at epoch 36 is 2.98170764696154\n",
      "validation loss at epoch 37 is 2.943871192953072\n",
      "validation loss at epoch 38 is 2.9036630918949315\n",
      "validation loss at epoch 39 is 2.8865116287240538\n",
      "validation loss at epoch 40 is 2.8792365042442465\n",
      "validation loss at epoch 41 is 2.8686633980795406\n",
      "validation loss at epoch 42 is 2.8640919326782046\n",
      "validation loss at epoch 43 is 2.8560150142563137\n",
      "validation loss at epoch 44 is 2.838123635722487\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "proteins = ProteinDataset(data=seqs)\n",
    "syn_proteins = ProteinDataset(data=test_seqs)\n",
    "\n",
    "EPOCHS=45\n",
    "ANP_det.train()\n",
    "optim = torch.optim.Adam(ANP_det.parameters(), lr = 1e-3)\n",
    "writer = SummaryWriter()\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "min_context = int(0.1 * seqs.shape[1])\n",
    "max_context = int(0.9 * seqs.shape[1])\n",
    "len_aa = seqs.shape[1]\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    loader = torch.utils.data.DataLoader(proteins, batch_size=32, shuffle=True)\n",
    "    overall_loss = 0\n",
    "    for i, batch in enumerate(loader):\n",
    "\n",
    "        \n",
    "        global_step+=1\n",
    "        (((x_context, y_context), x_target), y_target) = context_target_splitter(batch, min_context, max_context, len_aa, 1, 21)\n",
    "        \n",
    "        adjust_learning_rate(optim, global_step)\n",
    "        \n",
    "        y_pred, loss = ANP_det(x_context, y_context, x_target, y_target)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        writer.add_scalars('training_loss',{\n",
    "                    'loss':loss,\n",
    "                }, global_step)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(syn_proteins, batch_size=32, shuffle=False)\n",
    "    for batch in val_loader:\n",
    "        \n",
    "        (((x_context, y_context), x_target), y_target) = context_target_splitter(batch, min_context, max_context, len_aa, 1, 21)\n",
    "        val_y_pred, val_loss = ANP_det(x_context, y_context, x_target, y_target)\n",
    "        overall_loss += val_loss.item()\n",
    "\n",
    "    print('validation loss at epoch {} is '.format(epoch) + str(overall_loss/(test_seqs.shape[0]*test_seqs.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "521f82d7-1948-482f-a40c-36373800bb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 59, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c57534f-1b51-481a-8cee-062a00576ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.6121e-02, 7.3778e-03, 7.5174e-03, 9.4540e-03, 2.5536e-02, 5.0070e-02,\n",
       "        1.2349e-01, 4.0074e-03, 3.9315e-03, 4.0233e-02, 2.4191e-01, 2.1097e-02,\n",
       "        9.9020e-03, 8.3307e-03, 7.9315e-04, 1.4710e-02, 1.1715e-02, 2.8449e-04,\n",
       "        3.7828e-02, 2.9031e-01, 6.5380e-02], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y_pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d853abfd-b7d9-419c-8606-e74108cf6226",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMINO_ACIDS = \"ARNDCQEGHILKMFPSTWYV-\"\n",
    "IDX_TO_AA = list(AMINO_ACIDS)\n",
    "AA_TO_IDX = {aa: i for i, aa in enumerate(IDX_TO_AA)}\n",
    "\n",
    "frequency_matrix = np.zeros((seqs.shape[1], len(AA_TO_IDX)))\n",
    "\n",
    "for i in range(seqs.shape[0]):\n",
    "    for j in range(seqs.shape[1]):\n",
    "        frequency_matrix[j,AA_TO_IDX[seqs[i,j]]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cae0478-1b5d-49a9-add8-a787504f8776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 668.,  280.,  248., ...,   63.,  342.,  260.],\n",
       "       [ 617.,  226.,  347., ...,  263.,  523.,  148.],\n",
       "       [ 402.,  212.,  245., ...,  117.,  748.,  106.],\n",
       "       ...,\n",
       "       [ 586.,  319.,  239., ...,  329., 1128.,  295.],\n",
       "       [ 394.,  255.,  299., ...,   56.,  310., 1194.],\n",
       "       [ 465.,  380.,  233., ...,   76.,  371., 1591.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31e7739b-9e08-482e-9ee3-0d58771ecd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([27.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_target[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47f0824e-2277-453e-a22e-f7d1423d3cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x169a15610>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(y_target[0,1])\n",
    "plt.plot(val_y_pred.detach().numpy()[0,1])\n",
    "plt.plot(frequency_matrix[27]/7865)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5227a892-1715-4e06-8755-7bb227835614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 59, 1])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c3b23b7e-5e9e-4d24-9841-d102ad529566",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentiveNeuralProcess_Latent(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_dim, \n",
    "        y_dim,\n",
    "        projected_dim,\n",
    "        d_hidden, \n",
    "        d_model,\n",
    "        heads,\n",
    "        latent_dim,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.linear_1 = torch.nn.Linear(x_dim + y_dim, projected_dim)\n",
    "        self.activation = torch.nn.SELU()\n",
    "\n",
    "        self.deterministic_self_mha_1 = MultiHeadedAttention(heads, projected_dim, projected_dim, projected_dim, d_hidden, projected_dim)\n",
    "        self.addnorm_1 = AddNorm(normalized_shape= projected_dim)\n",
    "        self.dropout_1 = torch.nn.Dropout(0.1)\n",
    "\n",
    "        self.deterministic_self_mha_2 = MultiHeadedAttention(heads, projected_dim, projected_dim, projected_dim, d_hidden, projected_dim)\n",
    "        self.addnorm_2 = AddNorm(normalized_shape=projected_dim)\n",
    "        self.dropout_2 = torch.nn.Dropout(0.1)\n",
    "\n",
    "        self.latent_linear_1 = torch.nn.Linear(x_dim + y_dim, projected_dim)\n",
    "\n",
    "        self.latent_self_mha_1 = MultiHeadedAttention(heads, projected_dim, projected_dim, projected_dim, d_hidden, projected_dim)\n",
    "        self.latent_addnorm_1 = AddNorm(normalized_shape= projected_dim)\n",
    "        self.latent_dropout_1 = torch.nn.Dropout(0.1)\n",
    "\n",
    "        self.latent_self_mha_2 = MultiHeadedAttention(heads, projected_dim, projected_dim, projected_dim, d_hidden, projected_dim)\n",
    "        self.latent_addnorm_2 = AddNorm(normalized_shape=projected_dim)\n",
    "        self.latent_dropout_2 = torch.nn.Dropout(0.1)\n",
    "\n",
    "        self.latent_mu = torch.nn.Linear(projected_dim, latent_dim)\n",
    "        self.latent_log_var = torch.nn.Linear(projected_dim, latent_dim)\n",
    "\n",
    "    \n",
    "        self.context_projection = torch.nn.Linear(x_dim, projected_dim)\n",
    "        self.target_projection = torch.nn.Linear(x_dim, projected_dim)\n",
    "        \n",
    "        self.cross_mha = MultiHeadedAttention(heads, projected_dim, projected_dim, projected_dim, d_hidden, projected_dim)\n",
    "\n",
    "        self.linear_2 = torch.nn.Linear(projected_dim + x_dim + latent_dim, projected_dim)\n",
    "        self.linear_3 = torch.nn.Linear(projected_dim + x_dim + latent_dim, projected_dim)\n",
    "        self.linear_4 = torch.nn.Linear(projected_dim + x_dim + latent_dim, projected_dim)\n",
    "        self.linear_5 = torch.nn.Linear(projected_dim + x_dim + latent_dim, y_dim)\n",
    "\n",
    "    def cross_entropy(self, x, y):\n",
    "        return torch.sum(-y * torch.log(x + 1e-6) - (1.-y)*torch.log(1. - x + 1e-6))\n",
    "\n",
    "    def reparam(self, z_mu, z_log_var):\n",
    "        return z_mu + torch.randn_like(z_log_var) * torch.exp(z_log_var/2.)\n",
    "\n",
    "    def kl_loss_calc(\n",
    "        self, z_mu_context, z_log_var_context,\n",
    "              z_mu_target,  z_log_var_target\n",
    "    ):\n",
    "        q_context = torch.distributions.Normal(z_mu_context, torch.exp(z_log_var_context/2))\n",
    "        q_target = torch.distributions.Normal(z_mu_target, torch.exp(z_log_var_target/2))\n",
    "        \n",
    "        kl = torch.distributions.kl.kl_divergence(q_context, q_target)\n",
    "        return kl\n",
    "\n",
    "    def forward(self, context_x, context_y, target_x, target_y = None):\n",
    "        context = torch.concat([context_x, context_y], dim=-1)\n",
    "        x_1 = self.activation(self.linear_1(context))\n",
    "\n",
    "        x_2, _ = self.deterministic_self_mha_1(x_1, x_1, x_1)\n",
    "        x_2    = self.addnorm_1(x_2, x_1)\n",
    "        x_2    = self.dropout_1(x_2)\n",
    "\n",
    "        x_3, _ = self.deterministic_self_mha_2(x_2, x_2, x_2)\n",
    "        x_3    = self.addnorm_2(x_3, x_2)\n",
    "        x_3    = self.dropout_2(x_2)\n",
    "\n",
    "        projected_context = self.context_projection(context_x)\n",
    "        projected_target  = self.target_projection(target_x)\n",
    "        \n",
    "        cross_attended,_ = self.cross_mha(projected_target, projected_context, x_3)\n",
    "\n",
    "        z_1 = self.latent_linear_1(context)\n",
    "\n",
    "        z_2, _ = self.latent_self_mha_1(z_1, z_1, z_1)\n",
    "        z_2    = self.latent_addnorm_1(z_2, z_1)\n",
    "        z_2    = self.latent_dropout_1(z_2)\n",
    "\n",
    "        z_3, _ = self.latent_self_mha_2(z_2, z_2, z_2)\n",
    "        z_3    = self.latent_addnorm_2(z_3, z_2)\n",
    "        z_3    = self.latent_dropout_2(z_3)\n",
    "\n",
    "        z_3 = torch.mean(z_3, dim=1)\n",
    "\n",
    "        z_mu = self.latent_mu(z_3)\n",
    "        z_log_var = self.latent_log_var(z_3)\n",
    "\n",
    "        z = self.reparam(z_mu, z_log_var)\n",
    "\n",
    "        z = z.unsqueeze(dim=1).tile([1, target_x.shape[1],1])\n",
    "\n",
    "        yhat = torch.concat([cross_attended, target_x, z], dim=-1)\n",
    "        yhat = self.activation(self.linear_2(yhat))\n",
    "\n",
    "        yhat = torch.concat([yhat, target_x, z], dim=-1)\n",
    "        yhat = self.activation(self.linear_3(yhat))\n",
    "\n",
    "        yhat = torch.concat([yhat, target_x, z], dim=-1)\n",
    "        yhat = self.activation(self.linear_4(yhat))\n",
    "\n",
    "        yhat = torch.concat([yhat, target_x, z], dim=-1)\n",
    "        yhat = self.linear_5(yhat)\n",
    "        yhat = torch.nn.Softmax(dim=-1)(yhat)\n",
    "\n",
    "        if target_y is not None:\n",
    "            cross_entropy = self.cross_entropy(yhat, target_y)\n",
    "            target = torch.concat([target_x, target_y], dim=-1)\n",
    "            target_1 = self.activation(self.latent_linear_1(target))\n",
    "\n",
    "            target_2, _ = self.latent_self_mha_1(target_1, target_1, target_1)\n",
    "            target_2    = self.latent_addnorm_1(target_2, target_1)\n",
    "            target_2    = self.latent_dropout_1(target_2)\n",
    "\n",
    "            target_3, _ = self.latent_self_mha_2(target_2, target_2, target_2)\n",
    "            target_3    = self.latent_addnorm_2(target_3, target_2)\n",
    "            target_3    = self.latent_dropout_2(target_3)\n",
    "\n",
    "            z_target    = torch.mean(target_3, dim=1)\n",
    "            target_z_mu = self.latent_mu(z_target)\n",
    "            target_z_log_var = self.latent_log_var(z_target)\n",
    "\n",
    "            kl_loss = torch.sum(self.kl_loss_calc(z_mu, z_log_var, target_z_mu, target_z_log_var))\n",
    "            \n",
    "            return yhat, cross_entropy + kl_loss\n",
    "        else:\n",
    "            return yhat, 0\n",
    "                                     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97b4fdd8-2e37-4e8e-ba6c-89f8e223355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANP_lat = AttentiveNeuralProcess_Latent(\n",
    "    1, 21, 128, 128, 128, 8, 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12dd3f3e-7c8e-4049-98fa-28738551ca8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttentiveNeuralProcess_Latent(\n",
       "  (linear_1): Linear(in_features=22, out_features=128, bias=True)\n",
       "  (activation): SELU()\n",
       "  (deterministic_self_mha_1): MultiHeadedAttention(\n",
       "    (attention): DotProductAttention()\n",
       "    (W_q): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_k): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_v): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_o): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  )\n",
       "  (addnorm_1): AddNorm(\n",
       "    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "  (deterministic_self_mha_2): MultiHeadedAttention(\n",
       "    (attention): DotProductAttention()\n",
       "    (W_q): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_k): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_v): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_o): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  )\n",
       "  (addnorm_2): AddNorm(\n",
       "    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "  (latent_linear_1): Linear(in_features=22, out_features=128, bias=True)\n",
       "  (latent_self_mha_1): MultiHeadedAttention(\n",
       "    (attention): DotProductAttention()\n",
       "    (W_q): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_k): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_v): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_o): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  )\n",
       "  (latent_addnorm_1): AddNorm(\n",
       "    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (latent_dropout_1): Dropout(p=0.1, inplace=False)\n",
       "  (latent_self_mha_2): MultiHeadedAttention(\n",
       "    (attention): DotProductAttention()\n",
       "    (W_q): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_k): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_v): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_o): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  )\n",
       "  (latent_addnorm_2): AddNorm(\n",
       "    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (latent_dropout_2): Dropout(p=0.1, inplace=False)\n",
       "  (latent_mu): Linear(in_features=128, out_features=4, bias=True)\n",
       "  (latent_log_var): Linear(in_features=128, out_features=4, bias=True)\n",
       "  (context_projection): Linear(in_features=1, out_features=128, bias=True)\n",
       "  (target_projection): Linear(in_features=1, out_features=128, bias=True)\n",
       "  (cross_mha): MultiHeadedAttention(\n",
       "    (attention): DotProductAttention()\n",
       "    (W_q): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_k): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_v): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (W_o): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  )\n",
       "  (linear_2): Linear(in_features=133, out_features=128, bias=True)\n",
       "  (linear_3): Linear(in_features=133, out_features=128, bias=True)\n",
       "  (linear_4): Linear(in_features=133, out_features=128, bias=True)\n",
       "  (linear_5): Linear(in_features=133, out_features=21, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANP_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e057219f-0f13-4215-bdbe-f75c7d6c907b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:40,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 0 is 3.55772761743595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:36,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 1 is 3.574536299785991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:40,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 2 is 3.547934505262708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:37,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 3 is 3.5495254068689115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:37,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 4 is 3.4900492105242384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:37,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 5 is 3.5465076034223824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:39,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 6 is 3.4800154483417614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:39,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 7 is 3.456097568745054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:41,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 8 is 3.596438067162322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:41,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 9 is 3.5130046925625336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:37,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 10 is 3.4532489738958523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:36,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 11 is 3.4210504860420086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:37,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 12 is 3.4123335222961826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:37,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 13 is 3.357143908340491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:39,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 14 is 3.303627122083351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:40,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 15 is 3.2731839911782785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:39,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 16 is 3.2310854019243287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:40,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 17 is 3.1987189481494807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:39,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 18 is 3.197216587409536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:41,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 19 is 3.118534228185385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:42,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 20 is 3.0963212734117653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:42,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 21 is 3.1087317962961967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:42,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 22 is 3.052243277587363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:39,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 23 is 3.0445006034487556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:40,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 24 is 3.021052861172188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:37,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 25 is 3.0186182664710066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:39,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 26 is 2.9671289732960595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:45,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 27 is 2.978053847761653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:42,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 28 is 2.9644481864488683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:39,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 29 is 2.9266055033738283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:38,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 30 is 2.9216270703885865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:40,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 31 is 2.9050904282798466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:39,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 32 is 2.893415754789878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:37,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 33 is 2.899412250887529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:41,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss at epoch 34 is 2.8938244266868938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "237it [00:39,  5.72it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "proteins = ProteinDataset(data=seqs)\n",
    "syn_proteins = ProteinDataset(data=test_seqs)\n",
    "\n",
    "EPOCHS=45\n",
    "ANP_lat.train()\n",
    "optim = torch.optim.Adam(ANP_lat.parameters(), lr = 1e-3)\n",
    "writer = SummaryWriter()\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "min_context = int(0.1 * seqs.shape[1])\n",
    "max_context = int(0.9 * seqs.shape[1])\n",
    "len_aa = seqs.shape[1]\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    loader = torch.utils.data.DataLoader(proteins, batch_size=32, shuffle=True)\n",
    "    overall_loss = 0\n",
    "    for i, batch in tqdm(enumerate(loader)):\n",
    "        ANP_lat.train()\n",
    "        \n",
    "        global_step+=1\n",
    "        (((x_context, y_context), x_target), y_target) = context_target_splitter(batch, min_context, max_context, len_aa, 1, 21)\n",
    "        \n",
    "        adjust_learning_rate(optim, global_step)\n",
    "        \n",
    "        y_pred, loss = ANP_lat(x_context, y_context, x_target, y_target)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        writer.add_scalars('training_loss',{\n",
    "                    'loss':loss,\n",
    "                }, global_step)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(syn_proteins, batch_size=32, shuffle=False)\n",
    "    for batch in val_loader:\n",
    "        ANP_lat.eval()\n",
    "        (((x_context, y_context), x_target), y_target) = context_target_splitter(batch, min_context, max_context, len_aa, 1, 21)\n",
    "        val_y_pred, val_loss = ANP_lat(x_context, y_context, x_target, y_target)\n",
    "        overall_loss += val_loss.item()\n",
    "\n",
    "    print('validation loss at epoch {} is '.format(epoch) + str(overall_loss/(test_seqs.shape[0]*test_seqs.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4fc72eea-afd1-4642-a6ef-6678a6f5d0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0725, -0.5524, -0.5552]],\n",
       "\n",
       "        [[-0.8216,  0.6530, -0.0530]],\n",
       "\n",
       "        [[ 1.7631, -1.6940,  0.9103]],\n",
       "\n",
       "        [[ 2.1919, -0.0126,  0.0225]],\n",
       "\n",
       "        [[-0.6425, -1.7878,  2.2622]],\n",
       "\n",
       "        [[ 1.0786,  0.0765, -1.6339]],\n",
       "\n",
       "        [[-0.0836,  0.1963,  0.6273]],\n",
       "\n",
       "        [[ 0.7639,  0.3908,  1.4168]],\n",
       "\n",
       "        [[ 0.0147,  0.4423,  0.0785]],\n",
       "\n",
       "        [[ 1.1422,  1.0022, -0.1402]]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "15edf906-f55c-4ef0-b91e-3f2d9e7ad6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_test = torch.randn((10,5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1c5bec55-bebd-48f7-a523-057995c41dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.7885e-01,  1.8503e+00,  4.2787e-01],\n",
       "         [ 1.0071e+00,  1.4661e+00, -1.0260e-01],\n",
       "         [-1.3728e+00,  1.9242e+00, -6.2077e-01],\n",
       "         [-6.5727e-01, -7.5758e-01,  5.4797e-01],\n",
       "         [-1.0862e+00,  1.4214e+00, -1.4982e-01]],\n",
       "\n",
       "        [[-7.6549e-01,  1.5078e-01,  2.9107e-04],\n",
       "         [-2.7137e-01, -1.8251e+00,  1.6859e+00],\n",
       "         [-2.1129e+00,  2.3690e+00,  8.0102e-01],\n",
       "         [ 2.6335e-02,  1.9552e-01, -4.6229e-01],\n",
       "         [-2.7230e+00, -1.3442e+00, -8.8763e-01]],\n",
       "\n",
       "        [[ 5.1638e-01,  7.2710e-01, -1.8898e+00],\n",
       "         [-3.2572e-01,  1.0587e+00, -9.0792e-01],\n",
       "         [-1.1495e+00,  4.6414e-01, -4.8468e-01],\n",
       "         [ 1.0646e+00,  4.4712e-01, -6.7189e-01],\n",
       "         [-9.7373e-01, -3.1889e-01, -1.9782e+00]],\n",
       "\n",
       "        [[ 1.4106e+00,  8.3720e-01,  2.1635e-01],\n",
       "         [-1.3530e+00,  2.7244e-01,  8.5228e-01],\n",
       "         [-2.9217e+00,  4.1772e-03,  9.2262e-01],\n",
       "         [ 1.2403e+00,  5.4462e-01, -1.6630e-01],\n",
       "         [-5.1164e-01,  1.2458e+00,  9.4213e-01]],\n",
       "\n",
       "        [[ 1.1896e+00,  1.0729e+00,  6.9343e-01],\n",
       "         [ 6.4366e-01,  8.5062e-01,  2.5932e-02],\n",
       "         [-7.4051e-01, -1.4823e+00, -1.8003e+00],\n",
       "         [ 4.7036e-01,  3.3106e-01,  1.3796e+00],\n",
       "         [ 3.8345e-01, -4.8187e-01,  9.6876e-01]],\n",
       "\n",
       "        [[-8.6573e-01, -9.9244e-02,  1.7295e-01],\n",
       "         [ 1.2011e+00, -1.9013e+00,  1.0202e-01],\n",
       "         [-6.1840e-01, -1.3834e+00,  3.3889e-01],\n",
       "         [-2.4261e-01, -3.6381e-01, -3.7161e-01],\n",
       "         [-2.9350e-01,  1.4247e+00,  1.7190e-01]],\n",
       "\n",
       "        [[-7.2174e-01,  2.1935e+00,  2.4837e+00],\n",
       "         [-1.2010e+00,  1.1538e+00,  1.2728e+00],\n",
       "         [ 2.3710e+00,  9.7967e-01,  4.2706e-01],\n",
       "         [ 3.7177e-01,  1.1626e+00,  6.1843e-02],\n",
       "         [-1.1670e-01, -2.0090e-02,  2.9228e-01]],\n",
       "\n",
       "        [[-1.1489e+00,  8.3289e-01, -4.0409e-01],\n",
       "         [-6.8746e-02,  1.5216e+00,  2.7866e-01],\n",
       "         [ 1.2541e+00,  4.2922e-01, -3.7377e+00],\n",
       "         [ 6.9316e-01, -8.0008e-01,  1.0356e+00],\n",
       "         [-1.8558e-01,  1.3026e+00, -1.1576e+00]],\n",
       "\n",
       "        [[-1.7209e-01,  4.9787e-01, -2.8419e-01],\n",
       "         [-1.5587e+00, -4.2459e-01,  9.7269e-03],\n",
       "         [ 2.5824e-01,  9.5018e-01, -1.5500e-01],\n",
       "         [ 4.5351e-01,  6.5553e-02,  8.9437e-01],\n",
       "         [ 6.8949e-02, -6.4023e-01,  6.9652e-01]],\n",
       "\n",
       "        [[ 1.4921e-01,  3.0085e-02, -2.6528e-02],\n",
       "         [-1.1841e+00,  1.2183e+00, -1.0966e+00],\n",
       "         [ 6.7315e-01,  3.3394e-01, -1.2807e+00],\n",
       "         [-1.5279e-01, -1.1339e+00,  9.1868e-01],\n",
       "         [-5.2404e-01,  1.5888e+00, -1.0171e+00]]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "026fcbf3-620c-4cc1-b49d-1783dd84e573",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 2. Expected size 1 but got size 5 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_test\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 2. Expected size 1 but got size 5 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "torch.concat([test, other_test], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5248da43-2e65-45e8-846f-98d5420800c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
