{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f342840-2b5c-4df3-96f5-ba4121b9217b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 10:51:30.341150: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from typing import Any\n",
    "from typing import Dict\n",
    "from typing import List\n",
    "from typing import Optional\n",
    "from typing import Tuple\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3dc52ab-802c-42d9-8039-54601e9f5724",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa = pd.read_csv('SH3_Full_Dataset_8_9_22.csv')\n",
    "msa['Type'].unique()\n",
    "naturals_msa = msa[msa['Type']=='Naturals']\n",
    "seqs = np.asarray([list(seq) for seq in naturals_msa['Sequences']])\n",
    "norm_re = np.asarray([re for re in naturals_msa['Norm_RE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27888367-901a-4806-abc9-eaa49a55dfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_aa_keys='-GALMFWKQESPVICYHRNDT'\n",
    "def fasta_to_df(fasta_file, aa_keys = default_aa_keys):\n",
    "    \"\"\"\n",
    "    creates one hot encoding of a fasta file using biopython's alignio.read process. \n",
    "    fasta_file : filepath leading to msa file in fasta format at hand\n",
    "    \"\"\"\n",
    "    column_names = []\n",
    "    column_names.extend(aa_keys)\n",
    "    msa=AlignIO.read(fasta_file, \"fasta\")\n",
    "    num_columns = len(msa[0].seq)\n",
    "    column_names = column_names*num_columns\n",
    "    column_names.append('sequence')\n",
    "    column_names.append('id')\n",
    "    init = np.zeros((len(msa), len(column_names)))\n",
    "    df = pd.DataFrame(init, columns = column_names)\n",
    "    df.sequence = df.sequence.astype(str)\n",
    "    df.id=df.id.astype(str)\n",
    "    \n",
    "    for row_num, alignment in tqdm(enumerate(msa)):\n",
    "        sequence = str(alignment.seq)\n",
    "        for index, char in enumerate(sequence):\n",
    "            place = aa_keys.find(char)\n",
    "            df.iloc[row_num, index*len(aa_keys) + place] = 1\n",
    "        \n",
    "        df.iloc[row_num,-2]=str(alignment.seq)\n",
    "        df.iloc[row_num,-1]=str(alignment.id)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36694fe9-1dbb-4d65-955b-b7ac66442a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_frequency_matrix(df, aa_keys = default_aa_keys):\n",
    "    \"\"\"takes one hot encoded msa and returns the frequency of each amino acid at each site\n",
    "    df : pandas dataframe whose columns are the one hot encoding of an msa\n",
    "    \"\"\"\n",
    "    num_columns=len(df['sequence'][0])\n",
    "    \n",
    "    frequency_matrix = np.zeros( (len(aa_keys) , num_columns) )\n",
    "    print('calcing sum')\n",
    "    freq=df.sum()\n",
    "    print('sum calced')\n",
    "    \n",
    "    num_entries=len(df)\n",
    "    len_aa_keys = len(aa_keys)\n",
    "    \n",
    "    for i in tqdm(range(len(aa_keys))):\n",
    "        for j in range(num_columns):\n",
    "            frequency_matrix[i, j] = freq[ i + len_aa_keys * j] / num_entries\n",
    "    \n",
    "    return frequency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a56afb3-264e-4061-89de-4fcfed56a236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11608it [01:53, 102.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calcing sum\n",
      "sum calced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 8724.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 17, 44]\n"
     ]
    }
   ],
   "source": [
    "from Bio import AlignIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from tqdm import tqdm\n",
    "vae_alignment = []\n",
    "phenotypes = []\n",
    "\n",
    "vae_data = msa[msa['Type']=='VAE'].reset_index()\n",
    "\n",
    "for r in range(len(vae_data)):\n",
    "    alignment = vae_data.loc[r]\n",
    "    if len(alignment['Sequences'])==62:\n",
    "        record = SeqRecord(seq = Seq(alignment['Sequences']), id = alignment['Header'])\n",
    "    \n",
    "    vae_alignment.append(record)\n",
    "    phenotypes.append(alignment['Norm_RE'])\n",
    "\n",
    "vae_alignment = AlignIO.MultipleSeqAlignment(vae_alignment)\n",
    "\n",
    "AlignIO.write(vae_alignment, 'vae_alignment.fasta', 'fasta')\n",
    "\n",
    "vae_df = fasta_to_df('vae_alignment.fasta')\n",
    "\n",
    "freq_matrix = create_frequency_matrix(vae_df)\n",
    "\n",
    "trim_positions = []\n",
    "\n",
    "for i in range(freq_matrix.shape[1]):\n",
    "    if 1 in freq_matrix[:,i]:\n",
    "        trim_positions.append(i)\n",
    "\n",
    "print(trim_positions)\n",
    "\n",
    "\n",
    "vae_alignment_trimmed = []\n",
    "\n",
    "\n",
    "for alignment in vae_alignment:\n",
    "    new_seq = ''\n",
    "    for i in range(62):\n",
    "        if i not in trim_positions:\n",
    "            new_seq+=alignment.seq[i]\n",
    "    re_alignment = SeqRecord(seq=Seq(new_seq), id = alignment.id)\n",
    "    vae_alignment_trimmed.append(re_alignment)\n",
    "\n",
    "vae_alignment_trimmed = AlignIO.MultipleSeqAlignment(vae_alignment_trimmed)\n",
    "\n",
    "AlignIO.write(vae_alignment_trimmed, 'vae_alignment_trimmed.fasta', 'fasta')\n",
    "\n",
    "test_seqs = np.asarray([list(str(alignment.seq)) for alignment in vae_alignment_trimmed])\n",
    "\n",
    "phenotypes = np.asarray(phenotypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9f2a007-0241-44a6-92f5-f953a4cc6610",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMINO_ACIDS = \"ARNDCQEGHILKMFPSTWYV-\"\n",
    "IDX_TO_AA = list(AMINO_ACIDS)\n",
    "AA_TO_IDX = {aa: i for i, aa in enumerate(IDX_TO_AA)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87be4a92-c990-4772-9513-06f7e6a9905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNPRegressionDescription = collections.namedtuple(\n",
    "    \"CNPRegressionDescription\",\n",
    "    (\"query\", \"target_y\", \"num_total_points\", \"num_context_points\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e2143ca-2b32-4e02-bcf4-0fc59583f6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['V', 'F', 'L', ..., 'A', 'P', 'V'],\n",
       "       ['P', 'V', 'I', ..., 'C', 'G', 'Q'],\n",
       "       ['K', 'A', 'R', ..., 'S', 'K', 'E'],\n",
       "       ...,\n",
       "       ['R', 'Q', 'S', ..., 'V', 'G', 'K'],\n",
       "       ['P', 'A', 'G', ..., 'R', 'D', 'M'],\n",
       "       ['L', 'D', 'P', ..., 'E', 'T', 'F']], dtype='<U1')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "70ae5876-66cb-488d-b522-0a147b80b7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.data = data\n",
    "\n",
    "        self.AMINO_ACIDS = \"ARNDCQEGHILKMFPSTWYV-\"\n",
    "        self.IDX_TO_AA = list(AMINO_ACIDS)\n",
    "        self.AA_TO_IDX = {aa: i for i, aa in enumerate(IDX_TO_AA)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        X = torch.unsqueeze(torch.arange(start = 0, end = self.data.shape[1]),-1)\n",
    "\n",
    "        Y = self.data[index]\n",
    "\n",
    "        one_hot_Y = torch.tensor(self._to_one_hot(Y))\n",
    "        return X, one_hot_Y\n",
    "\n",
    "    def _to_one_hot(self, seq):\n",
    "        one_hot_encoded = np.zeros((seq.shape[0],len(self.IDX_TO_AA)))\n",
    "\n",
    "        for index, char in enumerate(seq):\n",
    "            one_hot_encoded[index, self.AA_TO_IDX[char]]=1\n",
    "        return one_hot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "5c12d242-9ae0-4e03-aaa4-c6d1bc71504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "a3acd371-6f3f-428d-8ccb-3de08a0432bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "min_num_context = 5\n",
    "max_num_context = 55\n",
    "\n",
    "num_context = np.random.randint(min_num_context, max_num_context)\n",
    "print(num_context)\n",
    "num_target = np.random.randint(Y.shape[1]-max_num_context, max_num_context - num_context)\n",
    "print(num_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "157f224c-270b-4510-94f0-ee7df84506b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    X = batch[1][0]\n",
    "    Y = batch[1][1]\n",
    "\n",
    "    max_num_context = int(0.9 * Y.shape[1])\n",
    "    min_num_context = int(0.1 * Y.shape[1])\n",
    "\n",
    "    num_context = np.random.randint(min_num_context, max_num_context)\n",
    "\n",
    "    context_x = torch.zeros((X.shape[0], num_context, 1))\n",
    "    context_y = torch.zeros((Y.shape[0], num_context, Y.shape[2]))\n",
    "    target_x  = torch.zeros((X.shape[0], X.shape[1], 1))\n",
    "    target_y  = torch.zeros((X.shape[0], Y.shape[1], Y.shape[2]))\n",
    "\n",
    "    for idx in range(Y.shape[0]):\n",
    "        total_idx = np.random.choice(range(Y.shape[1]), Y.shape[1], replace=False)\n",
    "        c_idx = total_idx[:num_context]\n",
    "        t_idx = total_idx\n",
    "\n",
    "        context_x[idx] = torch.tensor(c_idx).unsqueeze(-1)\n",
    "        target_x[idx] = torch.tensor(t_idx).unsqueeze(-1)\n",
    "\n",
    "        context_y[idx] = Y[idx, c_idx,:]\n",
    "        target_y[idx] = Y[idx, t_idx,:]\n",
    "\n",
    "    return context_x, context_y, target_x, target_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "5369c921-290d-4d31-9a5c-57846ebea02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_target_splitter(batch, min_context, max_context, len_seq):\n",
    "\n",
    "    num_context = torch.randint(low=min_context, high=max_context, size=[1])\n",
    "\n",
    "    X, Y = batch\n",
    "\n",
    "    X_context = torch.zeros(size=(X.shape[0], num_context, X.shape[-1]))\n",
    "    Y_context = torch.zeros(size=(Y.shape[0], num_context, Y.shape[-1]))\n",
    "\n",
    "    \n",
    "    X_target = torch.zeros(size=(X.shape[0], len_seq - num_context, X.shape[-1]))\n",
    "    Y_target = torch.zeros(size=(Y.shape[0], len_seq - num_context, Y.shape[-1]))\n",
    "    \n",
    "    \n",
    "\n",
    "    for index in range(Y.shape[0]):\n",
    "        seq = Y[index]\n",
    "\n",
    "        \n",
    "        shuffled_indices = torch.randperm(len_seq)\n",
    "    \n",
    "        context_indices = shuffled_indices[:num_context]\n",
    "        target_indices = shuffled_indices[num_context:]\n",
    "        \n",
    "        X_context[index] = context_indices.unsqueeze(-1)\n",
    "        X_target[index]  = target_indices.unsqueeze(-1)\n",
    "        \n",
    "        Y_context[index] = seq[context_indices]\n",
    "        Y_target[index] = seq[target_indices]\n",
    "\n",
    "    return (((X_context, Y_context), X_target), Y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "cfa345c0-d5a3-4e27-a009-c6c490129261",
   "metadata": {},
   "outputs": [],
   "source": [
    "(((X_context, Y_context), X_target), Y_target) = context_target_splitter(batch, 3,55,59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "7c7a7fe8-8b74-4391-8f8c-b93954c5e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "6747b1de-1e85-4a9a-8419-8338930816a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in loader:\n",
    "    X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "ce2afa3f-db94-4c66-ab8e-ca0bef43799a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 59, 21])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1bbf2fcd-5411-403b-8f01-a9364ccfc909",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_context = int(0.1 * seqs.shape[1])\n",
    "max_context = int(0.9 * seqs.shape[1])\n",
    "len_aa = seqs.shape[1]\n",
    "\n",
    "\n",
    "for batch in loader:\n",
    "    (((X_context, Y_context), X_target), Y_target) = context_target_splitter(batch, min_context, max_context, len_aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "65bb5f3e-c4f8-4519-951e-b844153cb94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        input_size,\n",
    "        output_sizes,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_size = input_size\n",
    "        self.output_sizes = output_sizes\n",
    "        \n",
    "        self.mlp = torch.nn.Sequential()\n",
    "\n",
    "        self.mlp.add_module('input_layer', torch.nn.Linear(input_size, output_sizes[0]))\n",
    "        self.mlp.add_module('relu', torch.nn.ReLU())\n",
    "\n",
    "        for index in range(1, len(output_sizes)):\n",
    "            self.mlp.add_module('hidden_layer_{}'.format(index), torch.nn.Linear(output_sizes[index-1], output_sizes[index]))\n",
    "            self.mlp.add_module('relu_{}'.format(index+1), torch.nn.ReLU())\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.shape[-1] == self.input_size, \"Input to MLP not the correct dimension\"\n",
    "\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "891fa745-ad25-4608-b104-0fa625caf64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_layer = MLP(22,[128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "85a66d36-623e-4779-ac14-fe7184c078cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (input_layer): Linear(in_features=22, out_features=128, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d8e0b900-d962-4293-a145-618631139827",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(torch.nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def forward(self, queries, keys, values, d_k, mask=None):\n",
    "        scores = torch.matmul(queries, keys.transpose(-1,-2))/torch.sqrt(d_k)\n",
    "        if mask is not None:\n",
    "            scores += -1e9*mask\n",
    "        attention = torch.nn.Softmax(dim=-1)(scores)\n",
    "        return torch.matmul(attention, values), attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f8e63ca0-d8df-495c-ab87-ab98c153a6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12//8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "fbe47020-ec04-4afa-a4a9-43583a43db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 h,\n",
    "                 d_query, \n",
    "                 d_key,\n",
    "                 d_values,\n",
    "                 d_hidden,\n",
    "                 d_model,\n",
    "                 activation = torch.nn.ReLU,\n",
    "                 **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.attention = DotProductAttention()\n",
    "        self.heads = h\n",
    "        self.d_query = d_query\n",
    "        self.d_key = d_key\n",
    "        self.d_values = d_values\n",
    "        self.d_hidden = d_hidden\n",
    "        self.W_q = torch.nn.Linear(d_query, d_hidden*h)\n",
    "        self.W_k = torch.nn.Linear(d_key, d_hidden*h)\n",
    "        self.W_v = torch.nn.Linear(d_values, d_hidden*h)\n",
    "        self.W_o = torch.nn.Linear(d_hidden, d_model)    \n",
    "\n",
    "    def reshape_tensor(self, x, heads, flag):\n",
    "        if flag:\n",
    "            x = torch.reshape(x, shape = (x.shape[0], x.shape[1], heads, x.shape[2]//heads))\n",
    "            x = x.permute(0,2,1,3)\n",
    "        else:\n",
    "            x = x.transpose(-1,-2)\n",
    "            x = torch.reshape(x, shape = (x.shape[0], x.shape[1], x.shape[2]//heads))\n",
    "        return x\n",
    "\n",
    "    def forward(self, queries, keys, values, mask = None):\n",
    "        n_context = queries.shape[1]\n",
    "        n_target = keys.shape[1]\n",
    "\n",
    "        q_reshaped = self.reshape_tensor(self.W_q(queries), self.heads, True)\n",
    "        k_reshaped = self.reshape_tensor(self.W_k(keys), self.heads, True)\n",
    "        v_reshaped = self.reshape_tensor(self.W_v(values), self.heads, True)\n",
    "        \n",
    "        output, attention = self.attention(q_reshaped, k_reshaped, v_reshaped, torch.tensor(self.d_hidden), mask)\n",
    "\n",
    "        return self.W_o(output), output    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "63ce3fd8-c0d3-4a81-b73c-97d30d322985",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_encoder = [128]\n",
    "\n",
    "heads = 8\n",
    "input_dim = 22\n",
    "attention_input_dim = mlp_encoder[-1]\n",
    "d_hidden = 128\n",
    "\n",
    "output_mlp_decoder = [128,128,128,21]\n",
    "\n",
    "\n",
    "\n",
    "encoder = [MLP(input_dim, mlp_encoder),\n",
    "           MultiHeadedAttention(heads, attention_input_dim, attention_input_dim, attention_input_dim, d_hidden, d_hidden), \n",
    "           MultiHeadedAttention(heads, heads*d_hidden, heads*d_hidden, heads*d_hidden, d_hidden, d_hidden)\n",
    "          ]\n",
    "\n",
    "decoder = [MultiHeadedAttention(heads, d_hidden, d_hidden, heads*d_hidden, d_hidden, d_hidden),\n",
    "           MultiHeadedAttention(heads, heads*d_hidden, d_hidden, heads*d_hidden, d_hidden, d_hidden),\n",
    "           MLP(heads*d_hidden  + 1, output_mlp_decoder)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "29d0631b-d7b2-4504-830f-2ba48f533b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ANP = AttentiveNeuralProcess(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "92bdaedd-9247-44e3-9b48-15a6aa63a32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MultiHeadedAttention(\n",
       "   (attention): DotProductAttention()\n",
       "   (W_q): Linear(in_features=128, out_features=1024, bias=True)\n",
       "   (W_k): Linear(in_features=128, out_features=1024, bias=True)\n",
       "   (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "   (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       " ),\n",
       " MultiHeadedAttention(\n",
       "   (attention): DotProductAttention()\n",
       "   (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "   (W_k): Linear(in_features=128, out_features=1024, bias=True)\n",
       "   (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "   (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       " ),\n",
       " MLP(\n",
       "   (mlp): Sequential(\n",
       "     (input_layer): Linear(in_features=1025, out_features=128, bias=True)\n",
       "     (relu): ReLU()\n",
       "     (hidden_layer_1): Linear(in_features=128, out_features=128, bias=True)\n",
       "     (relu_2): ReLU()\n",
       "     (hidden_layer_2): Linear(in_features=128, out_features=128, bias=True)\n",
       "     (relu_3): ReLU()\n",
       "     (hidden_layer_3): Linear(in_features=128, out_features=21, bias=True)\n",
       "     (relu_4): ReLU()\n",
       "   )\n",
       " )]"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ANP.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "ab69d764-7ec6-439a-aa0e-b8a3d733eaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got here\n",
      "torch.Size([25, 7, 128])\n",
      "torch.Size([25, 52, 128])\n",
      "torch.Size([25, 52, 1024])\n",
      "got here\n",
      "torch.Size([25, 7, 1024])\n",
      "torch.Size([25, 52, 128])\n",
      "torch.Size([25, 52, 1024])\n"
     ]
    }
   ],
   "source": [
    "stuff = full_ANP(X_context, Y_context, X_target, Y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "c9ebc126-c0aa-4aa0-84ef-5c7dae6cab67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 7, 21])"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "517bca0f-103a-4377-8d9a-7c1358dcbd79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3440, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "4464f3cc-b347-4566-9e58-113e52268b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentiveNeuralProcess(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 encoder,\n",
    "                 decoder,\n",
    "                 **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.target_projection = MLP(1, [128,128,128,128])\n",
    "        self.context_projection = MLP(1, [128,128,128,128])\n",
    "\n",
    "    def forward(self, context_x, context_y, target_x, target_y = None):\n",
    "        concat_input = torch.concat([context_x, context_y], dim=-1)\n",
    "        encoder_input = self.encoder[0](concat_input)\n",
    "        for layer in self.encoder[1:]:\n",
    "            encoder_input, _ = layer(encoder_input, encoder_input, encoder_input)\n",
    "            encoder_input = encoder_input.permute((0,2,1,3)).reshape((encoder_input.shape[0], encoder_input.shape[2], encoder_input.shape[1]*encoder_input.shape[3]))\n",
    "\n",
    "        query = self.target_projection(target_x)\n",
    "        keys = self.context_projection(context_x)\n",
    "\n",
    "        for layer in self.decoder[:-1]:\n",
    "            print('got here')\n",
    "            print(query.shape)\n",
    "            print(keys.shape)\n",
    "            print(encoder_input.shape)\n",
    "            query , _ = layer(query, keys, encoder_input)\n",
    "            query = query.permute((0,2,1,3)).reshape((query.shape[0], query.shape[2], query.shape[1]*query.shape[3]))\n",
    "\n",
    "        concatenated_final_entry = torch.concat([query, target_x], dim=-1)\n",
    "        output = self.decoder[-1](concatenated_final_entry)\n",
    "\n",
    "        output = torch.nn.Softmax(dim=-1)(output)\n",
    "\n",
    "        if target_y is not None:\n",
    "            loss = self.cross_entropy_loss(output, target_y)\n",
    "            return output, loss\n",
    "        else:\n",
    "            return output\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    def cross_entropy_loss(self, output, target_y):\n",
    "        assert output.shape == target_y.shape\n",
    "\n",
    "        cross_entropy = torch.mean(torch.sum(-target_y * torch.log(output + 1e-6) - (1-target_y) * torch.log(1 - output + 1e-6), dim=1))\n",
    "        return cross_entropy\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "4325d5e0-724b-4158-afb0-afb626d073d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(((x_context, y_context), x_target), y_target) = context_target_splitter(batch, min_context, max_context, len_aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "caf196fc-54f2-48b4-b968-0053c5ac7590",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_context = torch.concat([x_context, y_context], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "35e8ebac-4103-4a54-870d-f90998dfe912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 44, 22])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "62f96f5f-e7bf-4a11-8d20-482c877ee399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 44, 22])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "def0873a-11ce-48b8-bd67-ef86e32788f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, K, V = full_context, full_context, full_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "d0fec60c-720c-4e92-b51b-8fb73ece5af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 44, 22])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "677f1f03-a27a-43d8-97c8-b8e6d41d39bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_x = 1\n",
    "d_y = 21\n",
    "heads = 8\n",
    "d_hidden = 128\n",
    "d_model = 256\n",
    "\n",
    "mha = MultiHeadedAttention(heads, 22,22,22, d_hidden, d_model)\n",
    "mlp = MLP(d_x+d_y, [d_hidden,d_hidden,heads*d_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "a211844a-0502-4c93-8e1f-03ecb1bff216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output, attention = mha(Q, K, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "a5fe9bc0-3204-45fd-a38f-d2519b5f89c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_reshaped = output.permute((0,2,1,3)).reshape((output.shape[0], output.shape[2], output.shape[1]*output.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "db90eace-0760-45c7-9fd6-1ee2051fe580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 8, 44, 256])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "6c9d8b24-8ca8-4fe0-8313-41c0f9d036c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 44, 2048])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "b38b915d-105f-459d-9bce-d2393157d677",
   "metadata": {},
   "outputs": [],
   "source": [
    "mha_2 = MultiHeadedAttention(heads, output_reshaped.shape[-1], output_reshaped.shape[-1], output_reshaped.shape[-1], d_hidden, d_model)\n",
    "output_second_layer, attention_2 = mha_2(output_reshaped, output_reshaped, output_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "658eef9b-fafa-4adb-8f5c-5d3116a99f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_second_layer_reshaped = output_second_layer.permute((0,2,1,3)).reshape((output_second_layer.shape[0], output_second_layer.shape[2],  output_second_layer.shape[1]* output_second_layer.shape[3])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "3a7b866e-a5c2-4866-887a-f3c21ce012e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 44, 2048])"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_second_layer_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "a4433b04-832b-450b-98d5-21f5d26a29ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_query = x_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "ad23f2d4-2060-4890-8c62-098104407f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_keys = x_context\n",
    "new_values = output_second_layer_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "480a61ee-6b06-4b25-a9c2-05c283f8709c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 15, 1])"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "31acd13a-cfcc-48c9-ad8a-5a9c3a7e95c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mha_cross_1 = MultiHeadedAttention(8, 1, 1, 2048, d_hidden, d_model)\n",
    "cross_out_1, _ = mha_cross_1(new_query, new_keys, new_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "77ae445a-7ce7-44ff-93a6-c020f5683d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_out_1_reshaped = cross_out_1.permute((0,2,1,3)).reshape((cross_out_1.shape[0], cross_out_1.shape[2], cross_out_1.shape[1]*cross_out_1.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "41e65a39-0580-4d1f-8921-a5846e0957b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 15, 2048])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_out_1_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "670017d8-0da2-42bc-a204-9d1839a3cfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_cross_out_1 = torch.concat([cross_out_1_reshaped, x_target], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ce78a-c1d4-419b-bc07-bb08af36ca09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "5d4414ce-5315-4e69-8c3c-9796b6083e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 15, 2049])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_cross_out_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "9eb2978c-cd96-4b9c-a4e7-50dcd8b714da",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_reshaped = output.permute((0,2,1,3)).reshape((output.shape[0], output.shape[2], output.shape[1]*output.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "f91e0537-8df0-4d97-93ed-2b68bf853605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 44, 2048])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "fcf32c3e-d1af-4c69-9b9f-c1d312b93410",
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MultiHeadedAttention(heads, 1,1,2048, d_hidden, d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "3e573bdc-8e4c-4f70-9625-9323df1c9262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 44, 1])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "384a7ae7-6d4f-4104-96bf-30184141778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output, _ = mha(new_query, new_keys, output_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5b07fee6-eb84-4adc-a48c-77a4e172bbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 8, 44, 256])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e820131f-cf39-45b0-aace-3bd8e6153cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 44, 1])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "259182f2-14d5-40bd-8c1d-0db5525087d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 44, 1])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "624814b9-7b4b-45ce-9c43-6a04eeaca6cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[210], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43md_values\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd_values' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4b5ee67d-5260-4379-9f4e-5831b81c11e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 42, 1])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "918cac20-d4ab-417c-943b-ad520ef34e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_keys = x_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "07e136d2-c138-4fcd-abd4-b4bc9cb619e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 17, 1])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ffd997e7-7929-441d-a1b4-294e97e49006",
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff = torch.matmul(new_query, new_keys.transpose(-1,-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b782c1b5-dad6-4935-a68d-df0ea687744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "randn_a = torch.randn((8,10,25))\n",
    "randn_b = torch.randn((8,25,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "157f6f03-3487-4db6-8256-b9ddd7080f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(randn_a, randn_b) == randn_a.bmm(randn_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1ac00c2d-f718-4790-841b-5b584ff502ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (17) must match the size of tensor b (256) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[144], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39mmatmul(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_keys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (17) must match the size of tensor b (256) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "torch.matmul(torch.matmul(new_query, new_keys.transpose(-1,-2)).unsqueeze(1) * output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d415ac1b-b450-4842-a3fb-da79d57fbbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 8, 17, 256])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3090e1bc-be4f-4a76-983e-2605a9aaca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_output = output.permute((0,2,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "571c3a3e-93d0-4640-8be0-e4a725ec1bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_output = reshaped_output.reshape((reshaped_output.shape[0], reshaped_output.shape[1], reshaped_output.shape[2]*reshaped_output.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5a6af8d6-2016-4391-9fc2-6e1a919c5b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_output = mlp(full_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9047208b-6cdd-43d8-b0f2-66a5354a9a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 7, 2048])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f9bde3f0-f666-49f3-be00-5cccb99e1b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 7, 2048])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "34784844-04ff-4dbd-b472-0005fdd44bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 2048])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(reshaped_output * mlp_output, dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1c7edfee-95c7-4016-9dfa-8b65c08566f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 8, 34, 1, 256])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.unsqueeze(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "28bae623-ff06-4a28-ac07-a9b2ddf8e368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 1, 34, 256])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tile(mlped_context.unsqueeze(1).unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706f79d3-5517-43aa-be70-10d8a9e3cbca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0c293db9-0a6e-488a-8142-360a79238c82",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [27200, 256] but got: [27200, 1].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlped_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [27200, 256] but got: [27200, 1]."
     ]
    }
   ],
   "source": [
    "torch.matmul(mlped_context.unsqueeze(1).unsqueeze(2), output.unsqueeze(-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0dfd2f16-b1ea-4996-b2e0-4a8cf72101f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 8, 34, 256])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c40d57be-24bc-45e9-96f5-d65250baa480",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = full_context.unsqueeze(-2).tile((1,1,full_context.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "333fde13-363a-4e3f-ac61-bdee8f12c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MultiHeadedAttention(8, 22, 128, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "27a18d1d-b417-4719-a8c7-e25b39efab29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 46, 22])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a31ceae9-ffe8-4b2a-b92c-113ebcc5c029",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiled_x_dim_1 = full_context.permute((0,2,1)).tile((1, full_context.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "725bd369-f7a8-4598-90e3-44526f9635a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1012, 46])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiled_x_dim_1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b9457545-f9e6-421f-9437-bcdce2680a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[51.],\n",
       "        [19.],\n",
       "        [44.],\n",
       "        [12.],\n",
       "        [10.],\n",
       "        [31.],\n",
       "        [ 2.],\n",
       "        [48.],\n",
       "        [52.],\n",
       "        [28.],\n",
       "        [14.],\n",
       "        [54.],\n",
       "        [39.],\n",
       "        [ 9.],\n",
       "        [56.],\n",
       "        [26.],\n",
       "        [50.],\n",
       "        [ 4.],\n",
       "        [34.],\n",
       "        [55.],\n",
       "        [40.],\n",
       "        [46.],\n",
       "        [36.],\n",
       "        [38.],\n",
       "        [58.],\n",
       "        [17.],\n",
       "        [ 0.],\n",
       "        [ 8.],\n",
       "        [43.],\n",
       "        [ 3.],\n",
       "        [ 1.],\n",
       "        [32.],\n",
       "        [11.],\n",
       "        [ 5.],\n",
       "        [13.],\n",
       "        [18.],\n",
       "        [57.],\n",
       "        [ 7.],\n",
       "        [20.],\n",
       "        [45.],\n",
       "        [35.],\n",
       "        [33.],\n",
       "        [47.],\n",
       "        [23.],\n",
       "        [22.],\n",
       "        [42.]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_x_context[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fa1b5df3-c6a7-4977-8fc6-59f80c952bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiled_x_dim_2 = tensor_x_context.tile((1, 1, tensor_x_context.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2379a466-e8f3-4ea0-b7e5-e283c3f3ace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MultiHeadedAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "04abf406-b6d8-4ae2-a17a-0ba493c5e864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 46, 46, 1])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiled_x_dim_1.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "16d23598-e3ac-445d-a682-2321d6fd4b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 46, 46, 1])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiled_x_dim_2.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a403d917-4bbf-4379-a8f8-89f8da83766e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d617342a-5f73-4aa2-996b-4f2c3e42b35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 46, 1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "849be201-59c0-4103-96f8-2e9d2896f105",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[51.],\n",
       "        [19.],\n",
       "        [44.],\n",
       "        ...,\n",
       "        [23.],\n",
       "        [22.],\n",
       "        [42.]],\n",
       "\n",
       "       [[44.],\n",
       "        [50.],\n",
       "        [26.],\n",
       "        ...,\n",
       "        [33.],\n",
       "        [49.],\n",
       "        [58.]],\n",
       "\n",
       "       [[13.],\n",
       "        [52.],\n",
       "        [14.],\n",
       "        ...,\n",
       "        [19.],\n",
       "        [53.],\n",
       "        [17.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[27.],\n",
       "        [47.],\n",
       "        [46.],\n",
       "        ...,\n",
       "        [34.],\n",
       "        [20.],\n",
       "        [19.]],\n",
       "\n",
       "       [[10.],\n",
       "        [ 1.],\n",
       "        [47.],\n",
       "        ...,\n",
       "        [51.],\n",
       "        [30.],\n",
       "        [37.]],\n",
       "\n",
       "       [[15.],\n",
       "        [24.],\n",
       "        [11.],\n",
       "        ...,\n",
       "        [41.],\n",
       "        [ 6.],\n",
       "        [32.]]], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3c3587ed-a429-45ec-ab85-78f0af306834",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_context = torch.concat((torch.tensor(x_context), torch.tensor(y_context)), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8c102392-53b2-4e8a-b740-9c6d0a74ad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, K, V = full_context, full_context, full_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a4a6c884-d4e7-40d7-aecc-c4800da3b11c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[51.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [19.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [44.,  0.,  1.,  ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [23.,  0.,  0.,  ...,  0.,  1.,  0.],\n",
       "          [22.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [42.,  1.,  0.,  ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[44.,  0.,  1.,  ...,  0.,  0.,  0.],\n",
       "          [50.,  1.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [26.,  0.,  0.,  ...,  0.,  1.,  0.],\n",
       "          ...,\n",
       "          [33.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [49.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [58.,  0.,  0.,  ...,  0.,  0.,  1.]],\n",
       " \n",
       "         [[13.,  1.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [52.,  0.,  0.,  ...,  1.,  0.,  0.],\n",
       "          [14.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [19.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [53.,  0.,  0.,  ...,  0.,  1.,  0.],\n",
       "          [17.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[27.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [47.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [46.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [34.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [20.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [19.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[10.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [47.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [51.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [30.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [37.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[15.,  1.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [24.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [11.,  0.,  0.,  ...,  1.,  0.,  0.],\n",
       "          ...,\n",
       "          [41.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 6.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [32.,  0.,  1.,  ...,  0.,  0.,  0.]]]),\n",
       " tensor([[[51.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [19.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [44.,  0.,  1.,  ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [23.,  0.,  0.,  ...,  0.,  1.,  0.],\n",
       "          [22.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [42.,  1.,  0.,  ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[44.,  0.,  1.,  ...,  0.,  0.,  0.],\n",
       "          [50.,  1.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [26.,  0.,  0.,  ...,  0.,  1.,  0.],\n",
       "          ...,\n",
       "          [33.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [49.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [58.,  0.,  0.,  ...,  0.,  0.,  1.]],\n",
       " \n",
       "         [[13.,  1.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [52.,  0.,  0.,  ...,  1.,  0.,  0.],\n",
       "          [14.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [19.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [53.,  0.,  0.,  ...,  0.,  1.,  0.],\n",
       "          [17.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[27.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [47.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [46.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [34.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [20.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [19.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[10.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [47.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [51.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [30.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [37.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[15.,  1.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [24.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [11.,  0.,  0.,  ...,  1.,  0.,  0.],\n",
       "          ...,\n",
       "          [41.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 6.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [32.,  0.,  1.,  ...,  0.,  0.,  0.]]]),\n",
       " tensor([[[51.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [19.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [44.,  0.,  1.,  ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [23.,  0.,  0.,  ...,  0.,  1.,  0.],\n",
       "          [22.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [42.,  1.,  0.,  ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[44.,  0.,  1.,  ...,  0.,  0.,  0.],\n",
       "          [50.,  1.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [26.,  0.,  0.,  ...,  0.,  1.,  0.],\n",
       "          ...,\n",
       "          [33.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [49.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [58.,  0.,  0.,  ...,  0.,  0.,  1.]],\n",
       " \n",
       "         [[13.,  1.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [52.,  0.,  0.,  ...,  1.,  0.,  0.],\n",
       "          [14.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [19.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [53.,  0.,  0.,  ...,  0.,  1.,  0.],\n",
       "          [17.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[27.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [47.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [46.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [34.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [20.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [19.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[10.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [47.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [51.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [30.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [37.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[15.,  1.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [24.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [11.,  0.,  0.,  ...,  1.,  0.,  0.],\n",
       "          ...,\n",
       "          [41.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 6.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [32.,  0.,  1.,  ...,  0.,  0.,  0.]]]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q, K, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b54195bf-6e3f-4a12-a77d-583251b768fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MultiHeadedAttention(8, 22, 128, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d8534d21-df2f-45b4-afc0-4c072bbf028e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "representation, _ =mha(Q, K, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4333f95d-5ab6-43ab-97b6-ed4b51611e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 8, 256])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6fa14346-ee8e-43b4-8f32-c38d3e41802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_reshaped = torch.reshape(representation, shape = (representation.shape[0], representation.shape[1]*representation.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dab26ba8-95e0-45e5-a4c6-8d119ab16fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 2048])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representation_reshaped.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53996796-04c1-45fe-ab44-f31d2b444fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "097aee60-1089-4610-9c19-f7c0fe760b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = torch.randn((10,5,4))\n",
    "K = torch.randn((10,5,4))\n",
    "V = torch.randn((10,5,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8bcf8da1-d913-4230-98c8-d323d188076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MultiHeadedAttention(8, 4, 16, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0626292b-5101-4627-9b70-b32b7264ca76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 8, 5, 16])\n"
     ]
    }
   ],
   "source": [
    "blah, other_blah = mha(Q, K, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c1692108-3990-444c-a964-defcf6ca72aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 8, 256])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blah.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "3215539e-b332-4db2-a45b-10793d1da48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_unsqueezed_1 = Q.unsqueeze(2)\n",
    "Q_unsqueezed_2 = Q.unsqueeze(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "11b236f3-7d1d-480c-b7d8-2c6129c54b7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "difference = Q_unsqueezed_1 - Q_unsqueezed_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "db794e1f-bb84-49e8-9778-2fcb1783ed3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000, -1.1733, -0.2043, -3.6985],\n",
       "          [ 1.1733,  0.0000,  0.9690, -2.5252],\n",
       "          [ 0.2043, -0.9690,  0.0000, -3.4942],\n",
       "          [ 3.6985,  2.5252,  3.4942,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.2828, -1.9960,  0.5130],\n",
       "          [-0.2828,  0.0000, -2.2788,  0.2302],\n",
       "          [ 1.9960,  2.2788,  0.0000,  2.5090],\n",
       "          [-0.5130, -0.2302, -2.5090,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.5370, -0.3218, -2.2304],\n",
       "          [-0.5370,  0.0000, -0.8589, -2.7674],\n",
       "          [ 0.3218,  0.8589,  0.0000, -1.9086],\n",
       "          [ 2.2304,  2.7674,  1.9086,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -1.5438, -2.6875,  1.5698],\n",
       "          [ 1.5438,  0.0000, -1.1437,  3.1136],\n",
       "          [ 2.6875,  1.1437,  0.0000,  4.2573],\n",
       "          [-1.5698, -3.1136, -4.2573,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -0.3065,  2.0844, -0.5693],\n",
       "          [ 0.3065,  0.0000,  2.3909, -0.2628],\n",
       "          [-2.0844, -2.3909,  0.0000, -2.6537],\n",
       "          [ 0.5693,  0.2628,  2.6537,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000, -1.0647,  0.4351, -3.0388],\n",
       "          [ 1.0647,  0.0000,  1.4998, -1.9741],\n",
       "          [-0.4351, -1.4998,  0.0000, -3.4739],\n",
       "          [ 3.0388,  1.9741,  3.4739,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -0.6100, -0.1626,  0.3179],\n",
       "          [ 0.6100,  0.0000,  0.4475,  0.9280],\n",
       "          [ 0.1626, -0.4475,  0.0000,  0.4805],\n",
       "          [-0.3179, -0.9280, -0.4805,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -1.1681, -1.5751, -1.1151],\n",
       "          [ 1.1681,  0.0000, -0.4070,  0.0530],\n",
       "          [ 1.5751,  0.4070,  0.0000,  0.4600],\n",
       "          [ 1.1151, -0.0530, -0.4600,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -0.6213, -1.6667, -0.7633],\n",
       "          [ 0.6213,  0.0000, -1.0454, -0.1420],\n",
       "          [ 1.6667,  1.0454,  0.0000,  0.9034],\n",
       "          [ 0.7633,  0.1420, -0.9034,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  1.7724,  0.8825,  1.6369],\n",
       "          [-1.7724,  0.0000, -0.8899, -0.1355],\n",
       "          [-0.8825,  0.8899,  0.0000,  0.7544],\n",
       "          [-1.6369,  0.1355, -0.7544,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  1.0377, -0.3471,  1.7797],\n",
       "          [-1.0377,  0.0000, -1.3848,  0.7420],\n",
       "          [ 0.3471,  1.3848,  0.0000,  2.1268],\n",
       "          [-1.7797, -0.7420, -2.1268,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -1.5023, -0.0322, -2.8849],\n",
       "          [ 1.5023,  0.0000,  1.4701, -1.3825],\n",
       "          [ 0.0322, -1.4701,  0.0000, -2.8527],\n",
       "          [ 2.8849,  1.3825,  2.8527,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.2503,  0.3766, -0.6927],\n",
       "          [-0.2503,  0.0000,  0.1263, -0.9430],\n",
       "          [-0.3766, -0.1263,  0.0000, -1.0693],\n",
       "          [ 0.6927,  0.9430,  1.0693,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -0.7297,  1.5017,  1.2629],\n",
       "          [ 0.7297,  0.0000,  2.2314,  1.9926],\n",
       "          [-1.5017, -2.2314,  0.0000, -0.2388],\n",
       "          [-1.2629, -1.9926,  0.2388,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -1.0297, -1.0649, -1.8922],\n",
       "          [ 1.0297,  0.0000, -0.0351, -0.8625],\n",
       "          [ 1.0649,  0.0351,  0.0000, -0.8274],\n",
       "          [ 1.8922,  0.8625,  0.8274,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000, -0.8126, -1.3907, -1.0379],\n",
       "          [ 0.8126,  0.0000, -0.5781, -0.2253],\n",
       "          [ 1.3907,  0.5781,  0.0000,  0.3528],\n",
       "          [ 1.0379,  0.2253, -0.3528,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -0.9156, -0.2346, -2.0239],\n",
       "          [ 0.9156,  0.0000,  0.6810, -1.1084],\n",
       "          [ 0.2346, -0.6810,  0.0000, -1.7894],\n",
       "          [ 2.0239,  1.1084,  1.7894,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  1.9833,  1.4132,  0.9736],\n",
       "          [-1.9833,  0.0000, -0.5700, -1.0096],\n",
       "          [-1.4132,  0.5700,  0.0000, -0.4396],\n",
       "          [-0.9736,  1.0096,  0.4396,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -0.5462, -0.2882, -0.0562],\n",
       "          [ 0.5462,  0.0000,  0.2580,  0.4900],\n",
       "          [ 0.2882, -0.2580,  0.0000,  0.2320],\n",
       "          [ 0.0562, -0.4900, -0.2320,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  2.4045,  0.7174, -0.1848],\n",
       "          [-2.4045,  0.0000, -1.6871, -2.5893],\n",
       "          [-0.7174,  1.6871,  0.0000, -0.9022],\n",
       "          [ 0.1848,  2.5893,  0.9022,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000, -0.3884, -0.0654, -0.6901],\n",
       "          [ 0.3884,  0.0000,  0.3229, -0.3017],\n",
       "          [ 0.0654, -0.3229,  0.0000, -0.6246],\n",
       "          [ 0.6901,  0.3017,  0.6246,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  1.8118,  1.5130,  1.2167],\n",
       "          [-1.8118,  0.0000, -0.2988, -0.5951],\n",
       "          [-1.5130,  0.2988,  0.0000, -0.2963],\n",
       "          [-1.2167,  0.5951,  0.2963,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -0.0209, -1.2375, -2.5241],\n",
       "          [ 0.0209,  0.0000, -1.2166, -2.5032],\n",
       "          [ 1.2375,  1.2166,  0.0000, -1.2866],\n",
       "          [ 2.5241,  2.5032,  1.2866,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  3.1327,  1.5088,  1.5793],\n",
       "          [-3.1327,  0.0000, -1.6238, -1.5534],\n",
       "          [-1.5088,  1.6238,  0.0000,  0.0704],\n",
       "          [-1.5793,  1.5534, -0.0704,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -0.5888,  0.1070, -0.7455],\n",
       "          [ 0.5888,  0.0000,  0.6959, -0.1567],\n",
       "          [-0.1070, -0.6959,  0.0000, -0.8525],\n",
       "          [ 0.7455,  0.1567,  0.8525,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000, -0.5979,  0.2901,  0.5436],\n",
       "          [ 0.5979,  0.0000,  0.8880,  1.1415],\n",
       "          [-0.2901, -0.8880,  0.0000,  0.2535],\n",
       "          [-0.5436, -1.1415, -0.2535,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -1.6919, -0.1321, -2.0898],\n",
       "          [ 1.6919,  0.0000,  1.5598, -0.3978],\n",
       "          [ 0.1321, -1.5598,  0.0000, -1.9577],\n",
       "          [ 2.0898,  0.3978,  1.9577,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -0.6284, -0.7567,  0.7342],\n",
       "          [ 0.6284,  0.0000, -0.1284,  1.3626],\n",
       "          [ 0.7567,  0.1284,  0.0000,  1.4910],\n",
       "          [-0.7342, -1.3626, -1.4910,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.9246, -0.3393,  0.9050],\n",
       "          [-0.9246,  0.0000, -1.2638, -0.0195],\n",
       "          [ 0.3393,  1.2638,  0.0000,  1.2443],\n",
       "          [-0.9050,  0.0195, -1.2443,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -2.5946, -2.8276, -0.5461],\n",
       "          [ 2.5946,  0.0000, -0.2330,  2.0484],\n",
       "          [ 2.8276,  0.2330,  0.0000,  2.2815],\n",
       "          [ 0.5461, -2.0484, -2.2815,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.7565,  1.5360,  0.8747],\n",
       "          [-0.7565,  0.0000,  0.7794,  0.1182],\n",
       "          [-1.5360, -0.7794,  0.0000, -0.6612],\n",
       "          [-0.8747, -0.1182,  0.6612,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -0.0571,  0.6312,  0.3134],\n",
       "          [ 0.0571,  0.0000,  0.6884,  0.3705],\n",
       "          [-0.6312, -0.6884,  0.0000, -0.3179],\n",
       "          [-0.3134, -0.3705,  0.3179,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -1.4890, -0.6957, -0.5742],\n",
       "          [ 1.4890,  0.0000,  0.7933,  0.9148],\n",
       "          [ 0.6957, -0.7933,  0.0000,  0.1216],\n",
       "          [ 0.5742, -0.9148, -0.1216,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  1.8095, -1.7323,  1.2277],\n",
       "          [-1.8095,  0.0000, -3.5418, -0.5818],\n",
       "          [ 1.7323,  3.5418,  0.0000,  2.9600],\n",
       "          [-1.2277,  0.5818, -2.9600,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -0.1171,  0.6533,  1.6817],\n",
       "          [ 0.1171,  0.0000,  0.7704,  1.7988],\n",
       "          [-0.6533, -0.7704,  0.0000,  1.0284],\n",
       "          [-1.6817, -1.7988, -1.0284,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  1.2772,  2.4151,  0.5908],\n",
       "          [-1.2772,  0.0000,  1.1379, -0.6864],\n",
       "          [-2.4151, -1.1379,  0.0000, -1.8243],\n",
       "          [-0.5908,  0.6864,  1.8243,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -1.3843, -3.0428, -2.4007],\n",
       "          [ 1.3843,  0.0000, -1.6585, -1.0164],\n",
       "          [ 3.0428,  1.6585,  0.0000,  0.6420],\n",
       "          [ 2.4007,  1.0164, -0.6420,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.6906,  0.3556,  1.1660],\n",
       "          [-0.6906,  0.0000, -0.3350,  0.4754],\n",
       "          [-0.3556,  0.3350,  0.0000,  0.8104],\n",
       "          [-1.1660, -0.4754, -0.8104,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.6239, -0.5006, -0.7185],\n",
       "          [-0.6239,  0.0000, -1.1245, -1.3424],\n",
       "          [ 0.5006,  1.1245,  0.0000, -0.2179],\n",
       "          [ 0.7185,  1.3424,  0.2179,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -1.0391, -1.0585, -0.3469],\n",
       "          [ 1.0391,  0.0000, -0.0194,  0.6922],\n",
       "          [ 1.0585,  0.0194,  0.0000,  0.7116],\n",
       "          [ 0.3469, -0.6922, -0.7116,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0785,  0.8067,  1.9850],\n",
       "          [-0.0785,  0.0000,  0.7281,  1.9064],\n",
       "          [-0.8067, -0.7281,  0.0000,  1.1783],\n",
       "          [-1.9850, -1.9064, -1.1783,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  1.8824, -1.0144,  1.1521],\n",
       "          [-1.8824,  0.0000, -2.8969, -0.7304],\n",
       "          [ 1.0144,  2.8969,  0.0000,  2.1665],\n",
       "          [-1.1521,  0.7304, -2.1665,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -1.1314,  1.2462, -1.4316],\n",
       "          [ 1.1314,  0.0000,  2.3776, -0.3002],\n",
       "          [-1.2462, -2.3776,  0.0000, -2.6778],\n",
       "          [ 1.4316,  0.3002,  2.6778,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -0.9648, -1.5740, -2.1020],\n",
       "          [ 0.9648,  0.0000, -0.6092, -1.1371],\n",
       "          [ 1.5740,  0.6092,  0.0000, -0.5279],\n",
       "          [ 2.1020,  1.1371,  0.5279,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.6770,  0.3952,  0.9899],\n",
       "          [-0.6770,  0.0000, -0.2818,  0.3129],\n",
       "          [-0.3952,  0.2818,  0.0000,  0.5947],\n",
       "          [-0.9899, -0.3129, -0.5947,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.2731, -1.5993,  0.9695],\n",
       "          [-0.2731,  0.0000, -1.8724,  0.6964],\n",
       "          [ 1.5993,  1.8724,  0.0000,  2.5688],\n",
       "          [-0.9695, -0.6964, -2.5688,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0944, -0.6884,  0.5271],\n",
       "          [-0.0944,  0.0000, -0.7828,  0.4327],\n",
       "          [ 0.6884,  0.7828,  0.0000,  1.2155],\n",
       "          [-0.5271, -0.4327, -1.2155,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -0.2198,  0.9588,  0.0764],\n",
       "          [ 0.2198,  0.0000,  1.1785,  0.2961],\n",
       "          [-0.9588, -1.1785,  0.0000, -0.8824],\n",
       "          [-0.0764, -0.2961,  0.8824,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -0.4151,  0.4544, -0.4272],\n",
       "          [ 0.4151,  0.0000,  0.8695, -0.0121],\n",
       "          [-0.4544, -0.8695,  0.0000, -0.8816],\n",
       "          [ 0.4272,  0.0121,  0.8816,  0.0000]],\n",
       "\n",
       "         [[ 0.0000, -0.7789, -0.1348, -0.7887],\n",
       "          [ 0.7789,  0.0000,  0.6441, -0.0098],\n",
       "          [ 0.1348, -0.6441,  0.0000, -0.6539],\n",
       "          [ 0.7887,  0.0098,  0.6539,  0.0000]]]])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "eea305e1-dcac-4953-b48c-e405cdde59a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9603,  1.2431, -1.0357,  1.4733]])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_unsqueezed_1[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "33df896e-6b06-4454-8469-677850382f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9603],\n",
       "        [ 1.2431],\n",
       "        [-1.0357],\n",
       "        [ 1.4733]])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_unsqueezed_2[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "91b2e604-d9fd-4d64-bfc5-ed3e30fa1c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.2828, -1.9960,  0.5130],\n",
       "        [-0.2828,  0.0000, -2.2788,  0.2302],\n",
       "        [ 1.9960,  2.2788,  0.0000,  2.5090],\n",
       "        [-0.5130, -0.2302, -2.5090,  0.0000]])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "3935d7d2-e50c-44e1-849c-0c42d5b7a071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 4, 1])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "721cf7e8-8f12-4da8-b159-89ff65d6bbee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.7462, -0.7099,  2.5379, -3.4653])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q[0][0] - Q[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "51b0e7d6-0a9a-4213-b2e1-95ec3ff421d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -1.1733, -0.2043, -3.6985],\n",
       "        [ 1.1733,  0.0000,  0.9690, -2.5252],\n",
       "        [ 0.2043, -0.9690,  0.0000, -3.4942],\n",
       "        [ 3.6985,  2.5252,  3.4942,  0.0000]])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Q_unsqueezed_1-Q_unsqueezed_2)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2e9cda2a-44d1-48e5-bd5a-c5be214f44a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_Q = torch.sum((Q*Q), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b1a9171c-021a-48cc-9036-42b29e384030",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_Q = Q.matmul(Q.transpose(-1,-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "759fc930-bd87-40e5-92e5-5176aba7fa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_Q_A = torch.unsqueeze(norm_Q,2).tile(1,1,5)\n",
    "norm_Q_B = torch.unsqueeze(norm_Q,1).tile(1,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "29b0dbfe-4b30-42ae-bf4e-44a764335d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_dists = (norm_Q_A + norm_Q_B - 2 * pairwise_Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "733903ac-601b-4e80-bd57-99018c61bb7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, 10.0702,  1.6816,  9.2205,  4.1929],\n",
       "        [10.0702,  0.0000,  4.4489, 16.1165, 12.6896],\n",
       "        [ 1.6816,  4.4489,  0.0000,  8.8964,  7.0335],\n",
       "        [ 9.2205, 16.1165,  8.8964,  0.0000,  8.0963],\n",
       "        [ 4.1929, 12.6896,  7.0335,  8.0963,  0.0000]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_dists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "029c7540-ba32-4834-9e10-d25850f0fc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.192918770641882"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(Q[0][0] - Q[0][4])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "22badf63-d848-4535-9fdc-90b8143e0b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.8102502911578995"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(Q[0].detach().numpy()[1])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f9bd0f63-d2f8-43f3-bbb6-10b3ef93bd00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 1])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_unsqueezed_1 = torch.tile(torch.unsqueeze((torch.sum((Q*Q), dim=-1)),2),(1,1,5))\n",
    "norm_unsqueezed_2 = torch.tile(torch.unsqueeze((torch.sum((Q*Q), dim=-1)),2),(1,1,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a2174cea-5db7-4aa9-8850-8d930c6c264e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 5])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze((torch.sum((Q*Q), dim=-1)),1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3c8149-7a61-4b25-a4c1-62eb7f37f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "88323eca-9013-44aa-a96c-a1bedfa08bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 5])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tile(torch.unsqueeze((torch.sum((Q*Q), dim=-1)),2),(1,1,5)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "00f4f489-e321-4db0-afe8-d73e6c559004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 5])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tile(torch.unsqueeze((torch.sum((Q*Q), dim=-1)),1),(1,5,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f6a2a8ff-7f71-42fd-91bf-f4680613eb85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 5])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff = torch.randn((10,5,4))\n",
    "other_stuff = torch.randn((10,5,4))\n",
    "\n",
    "\n",
    "torch.matmul(stuff, other_stuff.transpose(-1,-2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9f0c9250-5f31-476f-8775-21db5c20fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = DotProductAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "975a3b8d-d562-4767-ba2a-ab9d7dbb84a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = torch.tensor([[0.3367, 0.1288],[0.2345,0.2303],[-1.1229,-0.1863]])\n",
    "K = torch.tensor([[ 2.2082, -0.6380],\n",
    "        [ 0.4617,  0.2674],\n",
    "        [ 0.5349,  0.8094]])\n",
    "\n",
    "V = torch.tensor([[ 1.1103, -1.6898],\n",
    "        [-0.9890,  0.9580],\n",
    "        [ 1.3221,  0.8172]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "65ba4848-e967-42e2-8810-3b62f720a371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.5697, -0.1520],\n",
       "         [ 0.5379, -0.0265],\n",
       "         [ 0.2246,  0.5556]]),\n",
       " tensor([[0.4028, 0.2886, 0.3086],\n",
       "         [0.3538, 0.3069, 0.3393],\n",
       "         [0.1303, 0.4630, 0.4067]]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 3\n",
    "d_k = torch.tensor(2)\n",
    "\n",
    "attention(Q, K, V, d_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "464f27b0-6b45-48b9-8876-d8ea39fee950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 16])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[3, 16, 8, -1]' is invalid for input of size 48",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m mha \u001b[38;5;241m=\u001b[39m MultiHeadedAttention(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m128\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmha\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43mV\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/npf/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[68], line 30\u001b[0m, in \u001b[0;36mMultiHeadedAttention.forward\u001b[0;34m(self, queries, keys, values, mask)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, queries, keys, values, mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_q(queries)\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 30\u001b[0m     q_reshaped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_q\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     k_reshaped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreshape_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_k(keys), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     32\u001b[0m     v_reshaped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreshape_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_v(values), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[68], line 21\u001b[0m, in \u001b[0;36mMultiHeadedAttention.reshape_tensor\u001b[0;34m(self, x, heads, flag)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape_tensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, heads, flag):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flag:\n\u001b[0;32m---> 21\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[3, 16, 8, -1]' is invalid for input of size 48"
     ]
    }
   ],
   "source": [
    "mha = MultiHeadedAttention(8, 2, 2, 128)\n",
    "\n",
    "mha(Q,K,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "db3081eb-e032-412f-b192-f81a9ece4e1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "torch.Size() takes an iterable of 'int' (item 0 is 'Tensor')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: torch.Size() takes an iterable of 'int' (item 0 is 'Tensor')"
     ]
    }
   ],
   "source": [
    "torch.Size(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af88b7a4-a364-471d-90b5-01cd82c29755",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(\n",
    "        input_size,\n",
    "        output_sizes,\n",
    "        is_bias = True,\n",
    "        activation = torch.nn.ReLU,\n",
    "        dropout = 0,\n",
    "        is_res = False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self._output_sizes = output_sizes\n",
    "        self.activation = activation\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.res = is_res\n",
    "\n",
    "        self.to_hidden = torch.nn.Linear(input_size, self.output_sizes[0], bias=is_bias)\n",
    "        self.linears = torch.nn.ModuleList(\n",
    "            [\n",
    "                torch.nn.Linear(self.output_sizes[i-1], self.output_sizes[i], bias=is_bias)\n",
    "                for _ in range(1, len(self.output_sizes))\n",
    "            ]\n",
    "        )\n",
    "    def forward(self, x):\n",
    "\n",
    "        for linear in linears:\n",
    "            output_1 = self.linear(output)\n",
    "            output_1 = self.activation(output_1)\n",
    "            output_1 = self.dropout(output_1)\n",
    "            if self.is_res:\n",
    "                output = output_1 + output\n",
    "            else:\n",
    "                output = output_1\n",
    "        return output\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3363ae3-bc7f-4302-9883-66d57b3904c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_RBF(torch.nn.Module):\n",
    "    def __init__(\n",
    "        x_dim,\n",
    "        output_sizes = [128.128,128,128],\n",
    "        is_bias = True,\n",
    "        activation = torch.nn.ReLU,\n",
    "        dropout = 0\n",
    "        is_res = False\n",
    "    ):\n",
    "        self.mlp = MLP(\n",
    "            x_dim,\n",
    "            output_sizes,\n",
    "            is_bias,\n",
    "            activation,\n",
    "            dropout,\n",
    "            is_res)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" takes x : (batch_size, num_context, x_dim + y_dim)\n",
    "        passes through mlp : (batch_size, num_context, mlp_output_dim)\n",
    "        passes through reshaping: (batch_size, mlp_output_dim*num_context)\n",
    "        Computes radial basis function, returning (batch_size, mlp_output^2)\n",
    "        \"\"\"\n",
    "        x_mlp = self.mlp(x)\n",
    "\n",
    "        x_reshaped_mlp = torch.reshape(x, (x_mlp.shape[0], x_mlp.shape[1]*x_mlp.shape[2]))\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7ce3dc4f-af48-46be-b42b-001d794b017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff = torch.randn((10,5,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "132ff5c0-0195-464b-8791-47a32be57024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1892, -0.1593,  0.0150, -0.0488],\n",
       "         [ 0.2855,  1.1376, -1.3892, -0.5053],\n",
       "         [-0.0613,  1.3183, -1.3418,  0.8088],\n",
       "         [-1.0177, -0.9790, -0.4899, -2.2784],\n",
       "         [ 1.0995,  1.6432,  1.1753, -0.5345]],\n",
       "\n",
       "        [[ 0.7801, -1.0657,  0.2304,  0.2352],\n",
       "         [ 1.0238,  0.0708, -0.4076, -0.8022],\n",
       "         [-0.3727, -0.8060, -0.6630,  1.7373],\n",
       "         [-1.0747, -0.4488,  0.4065, -0.6092],\n",
       "         [ 1.0579,  2.1286,  0.0697,  2.7280]],\n",
       "\n",
       "        [[ 1.6939, -0.8498, -0.4778,  0.7137],\n",
       "         [ 0.2977, -0.7736,  0.2704, -0.2792],\n",
       "         [-1.3080,  2.2400, -0.7018,  0.2845],\n",
       "         [-0.2582,  0.2023, -1.8169,  1.6254],\n",
       "         [-0.9776,  0.1462, -1.2581,  1.1714]],\n",
       "\n",
       "        [[-0.1130,  1.6967,  0.5609, -1.6138],\n",
       "         [ 0.2231, -0.8121,  0.5768, -0.5012],\n",
       "         [ 1.1451,  0.7488,  2.2243, -0.6175],\n",
       "         [-0.8851, -0.4628, -0.4371,  0.7586],\n",
       "         [-0.1597, -0.1398,  0.0112, -1.4179]],\n",
       "\n",
       "        [[ 0.0439,  0.1806,  0.3941,  2.7421],\n",
       "         [ 3.0348,  0.4632, -0.9423,  0.6811],\n",
       "         [-0.7999, -0.8128,  0.8395, -2.2879],\n",
       "         [-0.4275, -1.5639,  0.8555,  1.0357],\n",
       "         [ 0.5861, -1.2474, -1.2081,  0.9055]],\n",
       "\n",
       "        [[ 1.7581,  0.8432, -0.0885, -0.9309],\n",
       "         [ 0.6297,  0.6979, -0.8764,  0.5488],\n",
       "         [-1.2051,  0.6981, -0.2659,  0.9988],\n",
       "         [ 1.2539,  0.1991,  2.2316, -2.6389],\n",
       "         [ 0.1747,  0.9076, -3.1572,  1.2967]],\n",
       "\n",
       "        [[-0.8307,  0.3647, -0.5400,  0.3925],\n",
       "         [ 1.0678,  1.4857, -0.1644,  0.0248],\n",
       "         [ 0.8510,  2.2786,  1.2799,  0.0410],\n",
       "         [ 1.2939,  1.6864,  0.9267, -0.9173],\n",
       "         [-0.3109, -2.0741, -0.9788,  0.7223]],\n",
       "\n",
       "        [[ 0.7007,  0.8799,  0.1869, -0.1783],\n",
       "         [-1.5680,  1.6159,  0.2497,  1.5342],\n",
       "         [-0.6670,  0.1413, -0.4323,  0.3122],\n",
       "         [ 2.0991,  0.5887, -0.9043,  0.0378],\n",
       "         [-0.8448, -0.8387,  0.4755, -2.5152]],\n",
       "\n",
       "        [[ 0.0146,  0.5768,  0.6508, -0.1612],\n",
       "         [-0.8093, -0.5968, -0.2462,  0.6076],\n",
       "         [-1.5589,  0.3297,  0.8051, -0.9469],\n",
       "         [ 1.6842, -0.2344,  0.0935,  1.3067],\n",
       "         [ 1.1471, -0.4747,  0.2180,  0.9392]],\n",
       "\n",
       "        [[-0.8180, -0.4794,  1.4782, -1.4482],\n",
       "         [ 1.3846, -0.5980, -1.6844, -1.1779],\n",
       "         [-0.4050, -0.3265,  1.3780,  0.1705],\n",
       "         [-0.0262,  0.6500,  1.5384,  1.0659],\n",
       "         [-0.8411, -0.5951, -1.4176,  0.5734]]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "355d7fc5-d0f7-4a5f-9c2b-041e7164ae9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[6, 2]' is invalid for input of size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mQ\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[6, 2]' is invalid for input of size 6"
     ]
    }
   ],
   "source": [
    "Q.view(6,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b5a945-d014-46b8-96f5-ba18496c89be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetConv(nn.Module):\n",
    "    def __init__(\n",
    "\n",
    "        x_dim, \n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        RadialBasisFunc = \n",
    "\n",
    "    ):\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
