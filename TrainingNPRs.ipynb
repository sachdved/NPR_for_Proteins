{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9f86ea0-6b36-460f-ba45-d1cc255a2c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "978094cd-732e-4088-9c0e-ace8bd345cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa = pd.read_csv('SH3_Full_Dataset_8_9_22.csv')\n",
    "msa['Type'].unique()\n",
    "naturals_msa = msa[msa['Type']=='Naturals']\n",
    "seqs = np.asarray([list(seq) for seq in naturals_msa['Sequences']])\n",
    "norm_re = np.asarray([re for re in naturals_msa['Norm_RE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c672ebb8-89f5-4731-9f10-8a7d91cb31a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_aa_keys='-GALMFWKQESPVICYHRNDT'\n",
    "def fasta_to_df(fasta_file, aa_keys = default_aa_keys):\n",
    "    \"\"\"\n",
    "    creates one hot encoding of a fasta file using biopython's alignio.read process. \n",
    "    fasta_file : filepath leading to msa file in fasta format at hand\n",
    "    \"\"\"\n",
    "    column_names = []\n",
    "    column_names.extend(aa_keys)\n",
    "    msa=AlignIO.read(fasta_file, \"fasta\")\n",
    "    num_columns = len(msa[0].seq)\n",
    "    column_names = column_names*num_columns\n",
    "    column_names.append('sequence')\n",
    "    column_names.append('id')\n",
    "    init = np.zeros((len(msa), len(column_names)))\n",
    "    df = pd.DataFrame(init, columns = column_names)\n",
    "    df.sequence = df.sequence.astype(str)\n",
    "    df.id=df.id.astype(str)\n",
    "    \n",
    "    for row_num, alignment in tqdm(enumerate(msa)):\n",
    "        sequence = str(alignment.seq)\n",
    "        for index, char in enumerate(sequence):\n",
    "            place = aa_keys.find(char)\n",
    "            df.iloc[row_num, index*len(aa_keys) + place] = 1\n",
    "        \n",
    "        df.iloc[row_num,-2]=str(alignment.seq)\n",
    "        df.iloc[row_num,-1]=str(alignment.id)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cc3e7d7-3c19-4baf-b88a-2f8997abe037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_frequency_matrix(df, aa_keys = default_aa_keys):\n",
    "    \"\"\"takes one hot encoded msa and returns the frequency of each amino acid at each site\n",
    "    df : pandas dataframe whose columns are the one hot encoding of an msa\n",
    "    \"\"\"\n",
    "    num_columns=len(df['sequence'][0])\n",
    "    \n",
    "    frequency_matrix = np.zeros( (len(aa_keys) , num_columns) )\n",
    "    print('calcing sum')\n",
    "    freq=df.sum()\n",
    "    print('sum calced')\n",
    "    \n",
    "    num_entries=len(df)\n",
    "    len_aa_keys = len(aa_keys)\n",
    "    \n",
    "    for i in tqdm(range(len(aa_keys))):\n",
    "        for j in range(num_columns):\n",
    "            frequency_matrix[i, j] = freq[ i + len_aa_keys * j] / num_entries\n",
    "    \n",
    "    return frequency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65e356c6-bdbc-48b3-b46f-b4996d5a9e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11608it [02:01, 95.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calcing sum\n",
      "sum calced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 7722.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 17, 44]\n"
     ]
    }
   ],
   "source": [
    "from Bio import AlignIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from tqdm import tqdm\n",
    "vae_alignment = []\n",
    "phenotypes = []\n",
    "\n",
    "vae_data = msa[msa['Type']=='VAE'].reset_index()\n",
    "\n",
    "for r in range(len(vae_data)):\n",
    "    alignment = vae_data.loc[r]\n",
    "    if len(alignment['Sequences'])==62:\n",
    "        record = SeqRecord(seq = Seq(alignment['Sequences']), id = alignment['Header'])\n",
    "    \n",
    "    vae_alignment.append(record)\n",
    "    phenotypes.append(alignment['Norm_RE'])\n",
    "\n",
    "vae_alignment = AlignIO.MultipleSeqAlignment(vae_alignment)\n",
    "\n",
    "AlignIO.write(vae_alignment, 'vae_alignment.fasta', 'fasta')\n",
    "\n",
    "vae_df = fasta_to_df('vae_alignment.fasta')\n",
    "\n",
    "freq_matrix = create_frequency_matrix(vae_df)\n",
    "\n",
    "trim_positions = []\n",
    "\n",
    "for i in range(freq_matrix.shape[1]):\n",
    "    if 1 in freq_matrix[:,i]:\n",
    "        trim_positions.append(i)\n",
    "\n",
    "print(trim_positions)\n",
    "\n",
    "\n",
    "vae_alignment_trimmed = []\n",
    "\n",
    "\n",
    "for alignment in vae_alignment:\n",
    "    new_seq = ''\n",
    "    for i in range(62):\n",
    "        if i not in trim_positions:\n",
    "            new_seq+=alignment.seq[i]\n",
    "    re_alignment = SeqRecord(seq=Seq(new_seq), id = alignment.id)\n",
    "    vae_alignment_trimmed.append(re_alignment)\n",
    "\n",
    "vae_alignment_trimmed = AlignIO.MultipleSeqAlignment(vae_alignment_trimmed)\n",
    "\n",
    "AlignIO.write(vae_alignment_trimmed, 'vae_alignment_trimmed.fasta', 'fasta')\n",
    "\n",
    "test_seqs = np.asarray([list(str(alignment.seq)) for alignment in vae_alignment_trimmed])\n",
    "\n",
    "phenotypes = np.asarray(phenotypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce375b1f-4ad5-42a1-8bbe-d317d1cdc072",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMINO_ACIDS = \"ARNDCQEGHILKMFPSTWYV-\"\n",
    "IDX_TO_AA = list(AMINO_ACIDS)\n",
    "AA_TO_IDX = {aa: i for i, aa in enumerate(IDX_TO_AA)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15cc2b30-3041-4590-b744-edb397cbaed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NeuralProcessClasses import *\n",
    "from architecture_classes import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e95f873d-53f1-40b6-885f-58870892f9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_encoder = [128,128,128,128,128]\n",
    "mlp_decoder = [128,128,128,128,21]\n",
    "\n",
    "encoder = MLP(22, mlp_encoder)\n",
    "decoder = MLP(mlp_encoder[-1]+1, mlp_decoder)\n",
    "\n",
    "cnp = ConditionalNeuralProcess(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "611da36a-f204-477b-90e8-35986598f484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (input_layer): Linear(in_features=22, out_features=128, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (hidden_layer_1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (relu_2): ReLU()\n",
       "    (hidden_layer_2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (relu_3): ReLU()\n",
       "    (hidden_layer_3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (relu_4): ReLU()\n",
       "    (hidden_layer_4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (relu_5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnp.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4d5646d4-9737-4b0c-b3b9-b8f02ed80349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (input_layer): Linear(in_features=129, out_features=128, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (hidden_layer_1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (relu_2): ReLU()\n",
       "    (hidden_layer_2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (relu_3): ReLU()\n",
       "    (hidden_layer_3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (relu_4): ReLU()\n",
       "    (hidden_layer_4): Linear(in_features=128, out_features=21, bias=True)\n",
       "    (relu_5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnp.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "02aca907-2ccb-46f5-b832-5bd2fa8a0dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, step_num, warmup_step=4000):\n",
    "    lr = 0.001 * warmup_step**0.5 * min(step_num * warmup_step**-1.5, step_num**-0.5)\n",
    "    print(lr)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "67f91959-10f3-4fa1-bbb8-4e5e9436e0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7865it [04:07, 31.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7550, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7865it [04:11, 31.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9722, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7865it [04:04, 32.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7028, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7865it [03:59, 32.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5414, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7865it [03:58, 32.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.0075, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7865it [04:01, 32.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8221, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7865it [04:01, 32.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8691, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7865it [04:04, 32.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8628, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7865it [04:11, 31.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6604, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2328it [01:15, 30.98it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m     optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     32\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 33\u001b[0m     \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     writer\u001b[38;5;241m.\u001b[39madd_scalars(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,{\n\u001b[1;32m     36\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m:loss,\n\u001b[1;32m     37\u001b[0m             }, global_step)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n",
      "File \u001b[0;32m~/miniconda3/envs/npf/lib/python3.11/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/npf/lib/python3.11/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/miniconda3/envs/npf/lib/python3.11/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/npf/lib/python3.11/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/npf/lib/python3.11/site-packages/torch/optim/adam.py:391\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    389\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m     denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "proteins = ProteinDataset(data=seqs)\n",
    "\n",
    "EPOCHS=2000\n",
    "cnp.train()\n",
    "optim = torch.optim.Adam(cnp.parameters(), lr = 1e-3)\n",
    "writer = SummaryWriter()\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "min_context = int(0.1 * seqs.shape[1])\n",
    "max_context = int(0.9 * seqs.shape[1])\n",
    "len_aa = seqs.shape[1]\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    loader = torch.utils.data.DataLoader(proteins, batch_size=1, shuffle=True)\n",
    "    for i, batch in tqdm(enumerate(loader)):\n",
    "        \n",
    "        batch[0] = batch[0].tile((50,1,1))\n",
    "        batch[1] = batch[1].tile((50,1,1))\n",
    "        \n",
    "        global_step+=1\n",
    "        (((x_context, y_context), x_target), y_target) = context_target_splitter(batch, min_context, max_context, len_aa)\n",
    "        #adjust_learning_rate(optim, global_step)\n",
    "        \n",
    "        y_pred, loss = cnp(x_context, y_context, x_target, y_target)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        writer.add_scalars('training_loss',{\n",
    "                    'loss':loss,\n",
    "                }, global_step)\n",
    "\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e7cbdf5-41b7-41c1-9ae9-066e4ddd1291",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.2264],\n",
      "        [-0.9147],\n",
      "        [ 0.0068],\n",
      "        [-0.0336],\n",
      "        [ 0.7542],\n",
      "        [ 0.3175],\n",
      "        [-0.9394],\n",
      "        [ 0.7018],\n",
      "        [ 0.7636],\n",
      "        [-0.1279],\n",
      "        [ 0.2395],\n",
      "        [-0.1777],\n",
      "        [-0.6978],\n",
      "        [-0.6717],\n",
      "        [-0.4830],\n",
      "        [ 0.1246],\n",
      "        [-0.0510],\n",
      "        [-0.1662],\n",
      "        [ 0.8237],\n",
      "        [ 0.0263],\n",
      "        [-0.1226],\n",
      "        [-0.9183],\n",
      "        [-0.2341],\n",
      "        [-0.4515],\n",
      "        [-0.2532],\n",
      "        [ 0.6613],\n",
      "        [ 0.6219],\n",
      "        [-0.6336],\n",
      "        [-0.9330],\n",
      "        [ 0.8732],\n",
      "        [-0.7153],\n",
      "        [ 0.8014],\n",
      "        [-0.0295],\n",
      "        [ 0.7453],\n",
      "        [ 0.8805],\n",
      "        [ 0.8237],\n",
      "        [ 0.3090],\n",
      "        [-0.6496],\n",
      "        [-0.5646],\n",
      "        [ 0.7770],\n",
      "        [-0.9001],\n",
      "        [-0.5829],\n",
      "        [-0.6404],\n",
      "        [-0.4400],\n",
      "        [-0.9170],\n",
      "        [-0.7019],\n",
      "        [ 0.7960],\n",
      "        [-0.4236],\n",
      "        [ 0.1436],\n",
      "        [ 0.4853],\n",
      "        [ 0.6924],\n",
      "        [ 0.5530],\n",
      "        [ 0.2395],\n",
      "        [ 0.5401],\n",
      "        [-0.6860],\n",
      "        [-0.0484],\n",
      "        [-0.1065],\n",
      "        [ 0.6054],\n",
      "        [-0.7369],\n",
      "        [ 0.3790],\n",
      "        [-0.3371],\n",
      "        [-0.4029],\n",
      "        [-0.9108],\n",
      "        [-0.8641],\n",
      "        [ 0.6217],\n",
      "        [-0.3145],\n",
      "        [ 0.9550],\n",
      "        [-0.0630],\n",
      "        [-0.1933],\n",
      "        [ 0.7689],\n",
      "        [-0.9903],\n",
      "        [-0.0305],\n",
      "        [-0.9460],\n",
      "        [ 0.0987],\n",
      "        [-0.4654],\n",
      "        [-0.9253],\n",
      "        [ 0.8548],\n",
      "        [ 0.0393],\n",
      "        [ 0.1245],\n",
      "        [-0.3154],\n",
      "        [-0.5323],\n",
      "        [ 0.4194],\n",
      "        [ 0.0456],\n",
      "        [ 0.3418],\n",
      "        [-0.6988],\n",
      "        [ 0.7265],\n",
      "        [-0.8269],\n",
      "        [-0.2760],\n",
      "        [-0.7532],\n",
      "        [ 0.1328],\n",
      "        [ 0.6098],\n",
      "        [ 0.5983],\n",
      "        [-0.9550],\n",
      "        [ 0.6705],\n",
      "        [ 0.9236],\n",
      "        [ 0.2055],\n",
      "        [-0.0029],\n",
      "        [-0.7273],\n",
      "        [ 0.7148],\n",
      "        [-0.4777],\n",
      "        [-0.3251],\n",
      "        [-0.6754],\n",
      "        [-0.7478],\n",
      "        [-0.9450],\n",
      "        [-0.6781],\n",
      "        [-0.8150],\n",
      "        [ 0.7903],\n",
      "        [-0.5473],\n",
      "        [-0.4007],\n",
      "        [ 0.9794],\n",
      "        [ 0.4585],\n",
      "        [-0.7192],\n",
      "        [ 0.1138],\n",
      "        [-0.3317],\n",
      "        [ 0.9403],\n",
      "        [-0.3303],\n",
      "        [-0.6016],\n",
      "        [-0.9252],\n",
      "        [-0.0055],\n",
      "        [ 0.6083],\n",
      "        [-0.4875],\n",
      "        [-0.5952],\n",
      "        [-0.7989],\n",
      "        [-0.6008],\n",
      "        [ 0.3258],\n",
      "        [ 0.2688],\n",
      "        [ 0.6659],\n",
      "        [ 0.9103]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1915,  0.3346,  0.3011,  0.8997, -0.5365, -0.4373,  0.7908,  0.2802,\n",
      "         0.7384, -0.8134, -0.0733, -0.2081, -0.4559,  0.1062,  0.9340, -0.7454,\n",
      "         0.0760, -0.0789,  0.1382,  0.2057,  0.4729, -0.7139,  0.2557,  0.3717,\n",
      "         0.3373,  0.6294,  0.0894, -0.7209,  0.3434,  0.0473,  0.9798,  0.8527,\n",
      "        -0.8645,  0.5519, -0.7124,  0.6525,  0.4221,  0.7507, -0.2893,  0.6387,\n",
      "         0.7821, -0.4575, -0.3237, -0.9405, -0.1091, -0.0983, -0.3054,  0.7942,\n",
      "         0.7379, -0.8797, -0.2847, -0.4845,  0.2079,  0.8273,  0.3701, -0.8371,\n",
      "         0.4909,  0.8589, -0.0068, -0.2909,  0.7047,  0.8182,  0.8306, -0.6850,\n",
      "         0.7215,  0.9432, -0.3943,  0.8135, -0.3721, -0.1539,  0.3463, -0.7574,\n",
      "        -0.4405, -0.2141, -0.7458, -0.4761, -0.3097, -0.5969, -0.4021, -0.4145,\n",
      "         0.5829, -0.0343, -0.0170, -0.2508,  0.6584,  0.0837, -0.0904,  0.9163,\n",
      "        -0.8274, -0.5806, -0.7242, -0.2982, -0.0237, -0.5475, -0.7183, -0.6413,\n",
      "        -0.6261,  0.0202,  0.4928, -0.6029, -0.4017, -0.9145, -0.3852, -0.8947,\n",
      "        -0.8513,  0.5806,  0.4900, -0.8268, -0.7037,  0.0069, -0.1637, -0.7744,\n",
      "        -0.8977, -0.4142, -0.1419,  0.9376,  0.8781, -0.3224, -0.6580,  0.5331,\n",
      "        -0.1583, -0.3938, -0.9007,  0.3250, -0.4071,  0.9706, -0.7821,  0.8012],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0657, -0.0831, -0.0593,  ..., -0.0179,  0.0273, -0.0826],\n",
      "        [ 0.0544,  0.0544,  0.0868,  ..., -0.0880,  0.0233, -0.0395],\n",
      "        [-0.0667, -0.0515,  0.0657,  ..., -0.0853, -0.0084, -0.0548],\n",
      "        ...,\n",
      "        [ 0.0331,  0.0849,  0.0809,  ..., -0.0475, -0.0652, -0.0048],\n",
      "        [-0.0370,  0.0738, -0.0272,  ..., -0.0453, -0.0360,  0.0852],\n",
      "        [ 0.0203,  0.0717, -0.0422,  ..., -0.0803,  0.0242, -0.0670]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0311, -0.0818,  0.0008,  0.0178, -0.0023,  0.0586, -0.0339, -0.0345,\n",
      "         0.0695, -0.0414, -0.0438,  0.0009, -0.0708, -0.0363,  0.0634,  0.0842,\n",
      "         0.0019,  0.0405,  0.0298,  0.0757, -0.0511, -0.0725, -0.0081,  0.0501,\n",
      "         0.0764,  0.0786, -0.0812, -0.0408,  0.0821,  0.0324,  0.0505, -0.0826,\n",
      "         0.0253, -0.0832, -0.0341,  0.0728, -0.0262, -0.0606,  0.0443, -0.0422,\n",
      "        -0.0126,  0.0069,  0.0411,  0.0462, -0.0286,  0.0651, -0.0339, -0.0414,\n",
      "         0.0394,  0.0429, -0.0300, -0.0494, -0.0569, -0.0331, -0.0841,  0.0342,\n",
      "         0.0215,  0.0763,  0.0707, -0.0040,  0.0351, -0.0083, -0.0390,  0.0062,\n",
      "         0.0856,  0.0851,  0.0721,  0.0271, -0.0330,  0.0703,  0.0592, -0.0194,\n",
      "         0.0042, -0.0648, -0.0875,  0.0154,  0.0387,  0.0437,  0.0519,  0.0747,\n",
      "        -0.0521, -0.0351, -0.0035, -0.0192, -0.0090, -0.0449, -0.0146,  0.0327,\n",
      "         0.0164, -0.0348, -0.0127, -0.0070,  0.0518, -0.0156, -0.0443,  0.0097,\n",
      "         0.0004, -0.0862,  0.0398, -0.0877,  0.0186,  0.0269,  0.0736,  0.0702,\n",
      "         0.0222, -0.0521,  0.0772, -0.0473, -0.0180, -0.0310, -0.0653,  0.0622,\n",
      "        -0.0204, -0.0421, -0.0818,  0.0570,  0.0409, -0.0106, -0.0548,  0.0252,\n",
      "        -0.0499, -0.0121, -0.0752,  0.0438, -0.0170,  0.0583, -0.0738,  0.0766],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0032, -0.0137,  0.0620,  ...,  0.0764,  0.0819, -0.0023],\n",
      "        [-0.0244, -0.0858,  0.0005,  ...,  0.0775,  0.0477, -0.0053],\n",
      "        [ 0.0369, -0.0756,  0.0707,  ..., -0.0797,  0.0047, -0.0007],\n",
      "        ...,\n",
      "        [ 0.0222,  0.0185,  0.0610,  ...,  0.0045,  0.0715,  0.0573],\n",
      "        [ 0.0748, -0.0534, -0.0594,  ...,  0.0250, -0.0525,  0.0709],\n",
      "        [ 0.0869,  0.0164, -0.0622,  ..., -0.0799,  0.0079,  0.0068]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0653,  0.0042, -0.0061, -0.0346, -0.0083,  0.0314,  0.0237,  0.0232,\n",
      "        -0.0154, -0.0525, -0.0164, -0.0541,  0.0111, -0.0813, -0.0516, -0.0208,\n",
      "         0.0728,  0.0571,  0.0367, -0.0076,  0.0684, -0.0605,  0.0598,  0.0005,\n",
      "        -0.0770,  0.0427, -0.0214, -0.0763, -0.0596,  0.0125, -0.0218,  0.0749,\n",
      "        -0.0443,  0.0875, -0.0147,  0.0791, -0.0330,  0.0348, -0.0198,  0.0449,\n",
      "        -0.0075, -0.0035,  0.0555, -0.0668,  0.0524,  0.0424, -0.0273, -0.0510,\n",
      "        -0.0301, -0.0351, -0.0050, -0.0364, -0.0186, -0.0649, -0.0823, -0.0673,\n",
      "         0.0705,  0.0077,  0.0524,  0.0534, -0.0448, -0.0278,  0.0489,  0.0137,\n",
      "         0.0096, -0.0231,  0.0584, -0.0671,  0.0012, -0.0846, -0.0138,  0.0784,\n",
      "        -0.0652, -0.0509, -0.0416,  0.0706,  0.0394,  0.0095, -0.0656,  0.0688,\n",
      "         0.0672,  0.0330, -0.0493,  0.0507, -0.0555, -0.0614,  0.0193,  0.0312,\n",
      "         0.0161, -0.0186,  0.0698, -0.0410, -0.0244,  0.0846,  0.0105,  0.0395,\n",
      "        -0.0134, -0.0212,  0.0214, -0.0818, -0.0589, -0.0662,  0.0547, -0.0725,\n",
      "        -0.0508, -0.0449,  0.0202, -0.0375, -0.0550, -0.0551, -0.0575, -0.0710,\n",
      "        -0.0122, -0.0382, -0.0108,  0.0575,  0.0103,  0.0007,  0.0737, -0.0669,\n",
      "         0.0863,  0.0460, -0.0692, -0.0532,  0.0435,  0.0055,  0.0247,  0.0515],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0045, -0.0368, -0.0143,  ...,  0.0715, -0.0845,  0.0608],\n",
      "        [ 0.0104,  0.0682, -0.0314,  ..., -0.0387,  0.0720,  0.0858],\n",
      "        [-0.0436,  0.0836, -0.0217,  ...,  0.0472,  0.0742, -0.0811],\n",
      "        ...,\n",
      "        [ 0.0878, -0.0404, -0.0522,  ..., -0.0318, -0.0441, -0.0482],\n",
      "        [-0.0007,  0.0640, -0.0319,  ..., -0.0022,  0.0551, -0.0096],\n",
      "        [ 0.0770, -0.0513,  0.0434,  ..., -0.0290, -0.0062, -0.0285]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0707,  0.0570, -0.0035, -0.0167, -0.0185, -0.0306, -0.0414,  0.0342,\n",
      "         0.0093,  0.0604,  0.0781, -0.0626,  0.0472,  0.0320, -0.0027, -0.0154,\n",
      "         0.0133, -0.0352, -0.0295,  0.0450, -0.0203,  0.0118,  0.0714, -0.0623,\n",
      "        -0.0185, -0.0761,  0.0624,  0.0134, -0.0208, -0.0874,  0.0679, -0.0360,\n",
      "         0.0483,  0.0005, -0.0476,  0.0483,  0.0318,  0.0237,  0.0207, -0.0309,\n",
      "        -0.0544, -0.0026, -0.0659,  0.0581,  0.0415, -0.0593,  0.0084, -0.0045,\n",
      "        -0.0540, -0.0566, -0.0538, -0.0686, -0.0670,  0.0147,  0.0339, -0.0865,\n",
      "         0.0272,  0.0804,  0.0384, -0.0099, -0.0713,  0.0776,  0.0758,  0.0266,\n",
      "        -0.0785,  0.0799,  0.0299, -0.0157, -0.0385,  0.0342, -0.0731, -0.0225,\n",
      "         0.0330,  0.0630, -0.0589,  0.0225, -0.0594,  0.0134, -0.0069,  0.0348,\n",
      "        -0.0785, -0.0046,  0.0826, -0.0225, -0.0704, -0.0165,  0.0351,  0.0371,\n",
      "         0.0691,  0.0406, -0.0529,  0.0350,  0.0580, -0.0681, -0.0170,  0.0231,\n",
      "         0.0826,  0.0234,  0.0616, -0.0560,  0.0544, -0.0393,  0.0868, -0.0380,\n",
      "         0.0730,  0.0602, -0.0310, -0.0080, -0.0521, -0.0843, -0.0370,  0.0803,\n",
      "         0.0537,  0.0336, -0.0430,  0.0547, -0.0302,  0.0139, -0.0074,  0.0262,\n",
      "        -0.0840, -0.0524, -0.0207,  0.0269,  0.0427, -0.0363, -0.0128,  0.0479],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.7326],\n",
      "        [-0.9313],\n",
      "        [-0.5811],\n",
      "        [-0.1227],\n",
      "        [-0.2742],\n",
      "        [-0.9957],\n",
      "        [ 0.6981],\n",
      "        [ 0.3886],\n",
      "        [ 0.6796],\n",
      "        [-0.3970],\n",
      "        [-0.2037],\n",
      "        [-0.0696],\n",
      "        [ 0.7228],\n",
      "        [-0.2041],\n",
      "        [ 0.6597],\n",
      "        [ 0.2025],\n",
      "        [ 0.7547],\n",
      "        [-0.0241],\n",
      "        [-0.5717],\n",
      "        [-0.5282],\n",
      "        [ 0.5850],\n",
      "        [-0.6139],\n",
      "        [-0.7072],\n",
      "        [-0.9656],\n",
      "        [ 0.9727],\n",
      "        [-0.7588],\n",
      "        [-0.4076],\n",
      "        [ 0.5909],\n",
      "        [-0.3299],\n",
      "        [-0.3999],\n",
      "        [-0.9906],\n",
      "        [ 0.8506],\n",
      "        [-0.9166],\n",
      "        [ 0.5113],\n",
      "        [-0.7401],\n",
      "        [ 0.9230],\n",
      "        [ 0.1266],\n",
      "        [ 0.4330],\n",
      "        [ 0.7855],\n",
      "        [ 0.7527],\n",
      "        [-0.5109],\n",
      "        [ 0.1865],\n",
      "        [-0.7313],\n",
      "        [-0.2075],\n",
      "        [ 0.6671],\n",
      "        [ 0.2246],\n",
      "        [ 0.1889],\n",
      "        [-0.4517],\n",
      "        [ 0.0995],\n",
      "        [-0.3812],\n",
      "        [-0.8004],\n",
      "        [ 0.9272],\n",
      "        [-0.5305],\n",
      "        [ 0.6357],\n",
      "        [ 0.5684],\n",
      "        [ 0.7418],\n",
      "        [ 0.9789],\n",
      "        [ 0.4408],\n",
      "        [-0.1335],\n",
      "        [ 0.2070],\n",
      "        [-0.1127],\n",
      "        [-0.7088],\n",
      "        [ 0.5947],\n",
      "        [ 0.8595],\n",
      "        [ 0.2101],\n",
      "        [-0.5046],\n",
      "        [ 0.4876],\n",
      "        [ 0.9164],\n",
      "        [-0.3538],\n",
      "        [ 0.9867],\n",
      "        [-0.3336],\n",
      "        [-0.3651],\n",
      "        [-0.1568],\n",
      "        [ 0.5140],\n",
      "        [ 0.9648],\n",
      "        [ 0.2269],\n",
      "        [-0.8689],\n",
      "        [ 0.1364],\n",
      "        [ 0.1318],\n",
      "        [-0.6653],\n",
      "        [-0.3192],\n",
      "        [-0.7621],\n",
      "        [ 0.2304],\n",
      "        [ 0.8908],\n",
      "        [ 0.4691],\n",
      "        [ 0.4597],\n",
      "        [ 0.7549],\n",
      "        [ 0.9043],\n",
      "        [ 0.7817],\n",
      "        [-0.2567],\n",
      "        [-0.1455],\n",
      "        [-0.4299],\n",
      "        [-0.6893],\n",
      "        [-0.9979],\n",
      "        [-0.9911],\n",
      "        [ 0.2498],\n",
      "        [ 0.3288],\n",
      "        [-0.7020],\n",
      "        [ 0.1352],\n",
      "        [ 0.3294],\n",
      "        [ 0.4368],\n",
      "        [ 0.0659],\n",
      "        [ 0.3389],\n",
      "        [ 0.0903],\n",
      "        [ 0.8191],\n",
      "        [ 0.0383],\n",
      "        [ 0.5479],\n",
      "        [-0.3283],\n",
      "        [ 0.8888],\n",
      "        [-0.4368],\n",
      "        [-0.8487],\n",
      "        [ 0.2602],\n",
      "        [ 0.2974],\n",
      "        [ 0.6487],\n",
      "        [-0.0363],\n",
      "        [-0.1416],\n",
      "        [ 0.9523],\n",
      "        [-0.8918],\n",
      "        [-0.5706],\n",
      "        [-0.2363],\n",
      "        [-0.4717],\n",
      "        [ 0.8896],\n",
      "        [ 0.9555],\n",
      "        [ 0.5257],\n",
      "        [-0.7502],\n",
      "        [ 0.8882],\n",
      "        [-0.7285],\n",
      "        [ 0.5818]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4338,  0.2411, -0.9403, -0.9785, -0.5124,  0.5584, -0.1597, -0.2727,\n",
      "        -0.3536,  0.8697,  0.9364, -0.8771,  0.6056,  0.1759,  0.6003, -0.9363,\n",
      "         0.4255,  0.5515, -0.1783,  0.6815, -0.4764, -0.8431,  0.6466,  0.3099,\n",
      "        -0.8379,  0.2954, -0.8698, -0.2926,  0.5972,  0.1625,  0.9480, -0.2351,\n",
      "         0.1906, -0.9517,  0.9077, -0.3064, -0.1252,  0.0512, -0.5663,  0.3576,\n",
      "         0.6838, -0.2703,  0.7096, -0.4787,  0.3443,  0.0785,  0.7476, -0.6232,\n",
      "         0.0779,  0.6043, -0.3479,  0.6667,  0.3722,  0.6245,  0.2955, -0.2728,\n",
      "        -0.2155, -0.4901, -0.6870,  0.7192, -0.8149, -0.1642, -0.2015,  0.5987,\n",
      "         0.2181,  0.0992,  0.3637, -0.7358,  0.7486, -0.9792,  0.4410,  0.3183,\n",
      "        -0.5741,  0.5343, -0.2094, -0.3053, -0.1720, -0.1730, -0.3680,  0.3381,\n",
      "        -0.4741, -0.1654, -0.3230, -0.9711,  0.8582, -0.2075,  0.3887, -0.2281,\n",
      "        -0.7891, -0.6235,  0.3425, -0.8784,  0.0791,  0.9341, -0.0830,  0.1419,\n",
      "        -0.1765, -0.9519, -0.4779,  0.2877,  0.0770, -0.0990,  0.5720, -0.4408,\n",
      "         0.1195,  0.2216, -0.5459, -0.5080,  0.8084, -0.7149,  0.7978,  0.6047,\n",
      "         0.3950, -0.3288,  0.5816,  0.6662, -0.8224, -0.8866, -0.7779,  0.2728,\n",
      "         0.9895,  0.2803, -0.2276,  0.4040, -0.0582,  0.5727,  0.2285, -0.0921],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0292,  0.0319, -0.0553,  ..., -0.0019, -0.0664, -0.0854],\n",
      "        [-0.0005,  0.0574,  0.0637,  ..., -0.0253, -0.0046, -0.0512],\n",
      "        [ 0.0087,  0.0698,  0.0230,  ..., -0.0086, -0.0018, -0.0368],\n",
      "        ...,\n",
      "        [ 0.0593,  0.0286,  0.0059,  ...,  0.0637,  0.0035, -0.0575],\n",
      "        [-0.0871, -0.0176, -0.0282,  ..., -0.0690, -0.0033, -0.0588],\n",
      "        [ 0.0469, -0.0701,  0.0646,  ...,  0.0370,  0.0721,  0.0256]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0333, -0.0636, -0.0308, -0.0509,  0.0797,  0.0015, -0.0473,  0.0674,\n",
      "         0.0537, -0.0756, -0.0406,  0.0758, -0.0652,  0.0774, -0.0775, -0.0069,\n",
      "        -0.0649, -0.0644,  0.0656,  0.0052,  0.0585,  0.0700, -0.0514,  0.0150,\n",
      "         0.0111, -0.0712,  0.0325, -0.0570, -0.0680,  0.0856,  0.0347, -0.0835,\n",
      "        -0.0093, -0.0430, -0.0456, -0.0068, -0.0654,  0.0833,  0.0089, -0.0280,\n",
      "         0.0401,  0.0151, -0.0055, -0.0605,  0.0256,  0.0405, -0.0449,  0.0516,\n",
      "         0.0142, -0.0814,  0.0542,  0.0008, -0.0173, -0.0469,  0.0821,  0.0481,\n",
      "         0.0431,  0.0521, -0.0883, -0.0208, -0.0630, -0.0190, -0.0114,  0.0376,\n",
      "         0.0065, -0.0187,  0.0854,  0.0667,  0.0376, -0.0029, -0.0582, -0.0051,\n",
      "         0.0152, -0.0428,  0.0682,  0.0355, -0.0675,  0.0432,  0.0203, -0.0839,\n",
      "        -0.0288, -0.0652,  0.0092,  0.0466, -0.0245,  0.0642,  0.0101,  0.0216,\n",
      "         0.0599,  0.0267,  0.0095, -0.0490,  0.0326,  0.0653, -0.0861, -0.0819,\n",
      "         0.0244,  0.0477, -0.0486, -0.0197, -0.0789, -0.0155,  0.0011,  0.0627,\n",
      "         0.0125, -0.0511, -0.0641, -0.0215,  0.0230, -0.0011, -0.0861,  0.0288,\n",
      "         0.0090, -0.0218, -0.0325,  0.0478,  0.0574, -0.0042,  0.0112,  0.0881,\n",
      "        -0.0137,  0.0484, -0.0523,  0.0047,  0.0425,  0.0540, -0.0024, -0.0022],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0478,  0.0415, -0.0708,  ..., -0.0477,  0.0750,  0.0820],\n",
      "        [ 0.0014,  0.0364, -0.0580,  ..., -0.0312, -0.0482, -0.0607],\n",
      "        [ 0.0018, -0.0466,  0.0439,  ...,  0.0297, -0.0346, -0.0570],\n",
      "        ...,\n",
      "        [-0.0304, -0.0529,  0.0644,  ..., -0.0805, -0.0697,  0.0521],\n",
      "        [-0.0410,  0.0477,  0.0509,  ...,  0.0271, -0.0732, -0.0604],\n",
      "        [ 0.0566, -0.0354,  0.0037,  ..., -0.0559, -0.0666, -0.0798]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0406,  0.0651,  0.0086, -0.0552,  0.0252,  0.0452, -0.0007, -0.0586,\n",
      "        -0.0870, -0.0597, -0.0304, -0.0072,  0.0440,  0.0406,  0.0310, -0.0248,\n",
      "        -0.0446,  0.0402, -0.0030, -0.0371, -0.0472, -0.0597,  0.0225,  0.0103,\n",
      "        -0.0732, -0.0111,  0.0109,  0.0616, -0.0719, -0.0205,  0.0362, -0.0171,\n",
      "         0.0610,  0.0089, -0.0713, -0.0495, -0.0012, -0.0054, -0.0387, -0.0757,\n",
      "        -0.0548,  0.0505, -0.0846, -0.0804,  0.0342,  0.0468, -0.0001,  0.0310,\n",
      "        -0.0315,  0.0370, -0.0165,  0.0432,  0.0032,  0.0048, -0.0564, -0.0718,\n",
      "         0.0548,  0.0632,  0.0050,  0.0183,  0.0048, -0.0754,  0.0117, -0.0689,\n",
      "        -0.0327, -0.0352, -0.0453, -0.0150,  0.0573, -0.0299, -0.0372, -0.0863,\n",
      "        -0.0158, -0.0008, -0.0786, -0.0725,  0.0225, -0.0858,  0.0113, -0.0766,\n",
      "        -0.0290, -0.0629, -0.0439, -0.0055, -0.0031,  0.0656,  0.0030,  0.0655,\n",
      "         0.0396, -0.0749,  0.0463,  0.0316, -0.0807,  0.0849, -0.0707,  0.0641,\n",
      "         0.0328, -0.0070, -0.0861, -0.0260, -0.0356,  0.0446,  0.0163,  0.0023,\n",
      "        -0.0106,  0.0330,  0.0108,  0.0312,  0.0170,  0.0345, -0.0090, -0.0543,\n",
      "        -0.0473, -0.0399,  0.0417,  0.0834,  0.0073, -0.0540, -0.0245,  0.0150,\n",
      "        -0.0271,  0.0779,  0.0596, -0.0647, -0.0350,  0.0015, -0.0817,  0.0240],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0361, -0.0235, -0.0722,  ..., -0.0274, -0.0651, -0.0627],\n",
      "        [ 0.0600, -0.0126,  0.0866,  ..., -0.0814,  0.0708,  0.0810],\n",
      "        [-0.0877,  0.0775, -0.0113,  ...,  0.0103,  0.0304,  0.0083],\n",
      "        ...,\n",
      "        [ 0.0532, -0.0383,  0.0149,  ..., -0.0076,  0.0264, -0.0518],\n",
      "        [-0.0439, -0.0244,  0.0151,  ..., -0.0714, -0.0525, -0.0322],\n",
      "        [ 0.0256, -0.0872,  0.0230,  ..., -0.0803, -0.0370, -0.0669]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0533, -0.0197, -0.0741,  0.0317,  0.0248,  0.0615, -0.0149, -0.0009,\n",
      "        -0.0667, -0.0066,  0.0435,  0.0463, -0.0515,  0.0520,  0.0639, -0.0155,\n",
      "        -0.0568, -0.0475,  0.0189, -0.0438,  0.0019, -0.0357, -0.0054,  0.0838,\n",
      "         0.0488,  0.0344,  0.0479,  0.0020,  0.0263,  0.0519, -0.0430,  0.0791,\n",
      "         0.0834,  0.0371, -0.0684, -0.0421,  0.0799,  0.0528,  0.0373, -0.0499,\n",
      "         0.0638, -0.0475,  0.0158, -0.0317, -0.0430, -0.0280,  0.0684,  0.0644,\n",
      "        -0.0759, -0.0875, -0.0040,  0.0834,  0.0013, -0.0827,  0.0258,  0.0301,\n",
      "        -0.0594, -0.0716, -0.0604, -0.0357,  0.0247,  0.0200,  0.0266,  0.0844,\n",
      "        -0.0762,  0.0531,  0.0067, -0.0327, -0.0617, -0.0271, -0.0305,  0.0522,\n",
      "         0.0815, -0.0163, -0.0548,  0.0755, -0.0324, -0.0733, -0.0161,  0.0795,\n",
      "         0.0765, -0.0534,  0.0198, -0.0662, -0.0306,  0.0621,  0.0827, -0.0621,\n",
      "        -0.0495,  0.0441,  0.0586, -0.0561,  0.0245,  0.0780,  0.0049, -0.0035,\n",
      "         0.0251,  0.0037,  0.0828,  0.0515, -0.0658,  0.0151, -0.0139,  0.0390,\n",
      "        -0.0005, -0.0025, -0.0479, -0.0033,  0.0355, -0.0424, -0.0018, -0.0254,\n",
      "         0.0803, -0.0511,  0.0143, -0.0238, -0.0526,  0.0463, -0.0169,  0.0052,\n",
      "        -0.0785, -0.0568, -0.0672,  0.0674,  0.0772, -0.0797, -0.0109, -0.0334],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in full_ANP.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "56aa0a70-a929-4495-bded-8bf7bcac5287",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cnp(x_context, y_context, x_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e6673a49-c0a1-46de-b163-856a4db8a223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x122732610>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(y_pred[0][7].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3f47e8c7-193a-403f-92da-615fd511d116",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_encoder = [128]\n",
    "\n",
    "heads = 8\n",
    "input_dim = 22\n",
    "attention_input_dim = mlp_encoder[-1]\n",
    "d_hidden = 128\n",
    "\n",
    "output_mlp_decoder = [128,128,128,21]\n",
    "\n",
    "\n",
    "\n",
    "encoder = torch.nn.ModuleList([MLP(input_dim, mlp_encoder),\n",
    "           MultiHeadedAttention(heads, attention_input_dim, attention_input_dim, attention_input_dim, d_hidden, d_hidden), \n",
    "           MultiHeadedAttention(heads, heads*d_hidden, heads*d_hidden, heads*d_hidden, d_hidden, d_hidden)\n",
    "          ])\n",
    "\n",
    "decoder = torch.nn.ModuleList([MultiHeadedAttention(heads, d_hidden, d_hidden, heads*d_hidden, d_hidden, d_hidden),\n",
    "           MultiHeadedAttention(heads, heads*d_hidden, d_hidden, heads*d_hidden, d_hidden, d_hidden),\n",
    "           MLP(heads*d_hidden  + 1, output_mlp_decoder)\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "57c0d6d7-70b2-4a93-9aa8-03081fca3436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (input_layer): Linear(in_features=22, out_features=128, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9dc73829-a75d-4a54-9447-9c610e7ee49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (mlp): Sequential(\n",
       "    (input_layer): Linear(in_features=1025, out_features=128, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (hidden_layer_1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (relu_2): ReLU()\n",
       "    (hidden_layer_2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (relu_3): ReLU()\n",
       "    (hidden_layer_3): Linear(in_features=128, out_features=21, bias=True)\n",
       "    (relu_4): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d34b0ece-815f-4101-bc88-773acecb5284",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ANP = AttentiveNeuralProcess(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c7e457a9-110c-4f0a-91f9-03d5e1d80c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttentiveNeuralProcess(\n",
      "  (encoder): ModuleList(\n",
      "    (0): MLP(\n",
      "      (mlp): Sequential(\n",
      "        (input_layer): Linear(in_features=22, out_features=128, bias=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (1): MultiHeadedAttention(\n",
      "      (attention): DotProductAttention()\n",
      "      (W_q): Linear(in_features=128, out_features=1024, bias=True)\n",
      "      (W_k): Linear(in_features=128, out_features=1024, bias=True)\n",
      "      (W_v): Linear(in_features=128, out_features=1024, bias=True)\n",
      "      (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (2): MultiHeadedAttention(\n",
      "      (attention): DotProductAttention()\n",
      "      (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (W_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder): ModuleList(\n",
      "    (0): MultiHeadedAttention(\n",
      "      (attention): DotProductAttention()\n",
      "      (W_q): Linear(in_features=128, out_features=1024, bias=True)\n",
      "      (W_k): Linear(in_features=128, out_features=1024, bias=True)\n",
      "      (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (1): MultiHeadedAttention(\n",
      "      (attention): DotProductAttention()\n",
      "      (W_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (W_k): Linear(in_features=128, out_features=1024, bias=True)\n",
      "      (W_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (mlp): Sequential(\n",
      "        (input_layer): Linear(in_features=1025, out_features=128, bias=True)\n",
      "        (relu): ReLU()\n",
      "        (hidden_layer_1): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (relu_2): ReLU()\n",
      "        (hidden_layer_2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (relu_3): ReLU()\n",
      "        (hidden_layer_3): Linear(in_features=128, out_features=21, bias=True)\n",
      "        (relu_4): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (target_projection): MLP(\n",
      "    (mlp): Sequential(\n",
      "      (input_layer): Linear(in_features=1, out_features=128, bias=True)\n",
      "      (relu): ReLU()\n",
      "      (hidden_layer_1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (relu_2): ReLU()\n",
      "      (hidden_layer_2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (relu_3): ReLU()\n",
      "      (hidden_layer_3): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (relu_4): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (context_projection): MLP(\n",
      "    (mlp): Sequential(\n",
      "      (input_layer): Linear(in_features=1, out_features=128, bias=True)\n",
      "      (relu): ReLU()\n",
      "      (hidden_layer_1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (relu_2): ReLU()\n",
      "      (hidden_layer_2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (relu_3): ReLU()\n",
      "      (hidden_layer_3): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (relu_4): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(full_ANP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "424bf14b-7961-4859-ae99-f5db538e89a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins = ProteinDataset(data=seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3f2e0f24-4c4e-47de-be09-c12fe8996cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, step_num, warmup_step=4000):\n",
    "    lr = 0.001 * warmup_step**0.5 * min(step_num * warmup_step**-1.5, step_num**-0.5)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aaeb199d-2e10-487a-99e0-af7b2637e7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [02:37,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9636, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [02:39,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9399, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [02:43,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8894, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [02:41,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8938, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [02:43,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8505, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [02:53,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8952, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [02:47,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7953, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [02:45,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7594, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [03:01,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7445, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [02:52,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7620, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [04:41,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7553, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [04:24,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7123, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:03,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7973, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:22,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7283, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:41,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6530, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:42,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7753, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:50,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7068, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:56,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7528, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [06:24,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7650, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [06:53,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7495, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [08:08,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6869, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [21:23,  5.22s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7786, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [08:56,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7299, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [07:44,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6618, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [4:34:24, 66.93s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6765, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [11:17,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.0159, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:20,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9814, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [06:32,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9915, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:36,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9643, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:36,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9612, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:40,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9798, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [06:14,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9850, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [5:38:45, 82.62s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9353, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [7:07:13, 104.20s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9283, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:38,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9344, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:45,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9172, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:34,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9219, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [06:08,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9263, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [06:15,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8839, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [06:20,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9169, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:40,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9272, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:36,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9131, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:16,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9304, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [04:46,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9153, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [04:54,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9144, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:42,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9290, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:41,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9078, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:21,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9560, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [04:53,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8675, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [04:43,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9224, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [04:58,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8417, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:08,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8998, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:13,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8828, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [04:57,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8885, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [04:51,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9237, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:12,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8844, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:05,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8779, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [35:00,  8.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9003, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8525, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:09,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9012, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:13,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8800, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:23,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8186, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:06,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8649, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [04:56,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8511, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:05,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8657, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:19,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8424, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [04:55,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8882, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:05,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9530, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:12,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8738, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:18,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9495, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:11,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8673, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:02,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8945, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:10,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9568, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:18,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9163, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:11,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8630, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:05,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8762, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8256, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:05,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8916, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [04:59,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8729, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [05:31,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8497, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [04:39,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8694, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [04:19,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8812, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [04:10,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8437, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [04:06,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8708, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:12,  1.11s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "EPOCHS=2000\n",
    "full_ANP.train()\n",
    "optim = torch.optim.Adam(full_ANP.parameters(), lr = 1e-4)\n",
    "writer = SummaryWriter()\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "min_context = int(0.1 * seqs.shape[1])\n",
    "max_context = int(0.9 * seqs.shape[1])\n",
    "len_aa = seqs.shape[1]\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    loader = torch.utils.data.DataLoader(proteins, batch_size=32, shuffle=True)\n",
    "    for i, batch in tqdm(enumerate(loader)):\n",
    "        \n",
    "        global_step+=1\n",
    "        (((x_context, y_context), x_target), y_target) = context_target_splitter(batch, min_context, max_context, len_aa)\n",
    "        adjust_learning_rate(optim, global_step)\n",
    "        \n",
    "        y_pred, loss = full_ANP(x_context, y_context, x_target, y_target)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        writer.add_scalars('training_loss',{\n",
    "                    'loss':loss,\n",
    "                }, global_step)\n",
    "\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e5ace44-6bb8-4cab-9e92-c1d543e50a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = full_ANP(x_context, y_context, x_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "881f1427-000a-48a1-99a0-7338f1840196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0516, 0.0464, 0.0485,  ..., 0.0509, 0.0527, 0.0456],\n",
       "         [0.0514, 0.0463, 0.0483,  ..., 0.0506, 0.0523, 0.0457],\n",
       "         [0.0502, 0.0462, 0.0478,  ..., 0.0496, 0.0506, 0.0462],\n",
       "         ...,\n",
       "         [0.0517, 0.0464, 0.0485,  ..., 0.0509, 0.0528, 0.0455],\n",
       "         [0.0500, 0.0462, 0.0478,  ..., 0.0495, 0.0505, 0.0462],\n",
       "         [0.0514, 0.0463, 0.0483,  ..., 0.0506, 0.0522, 0.0457]],\n",
       "\n",
       "        [[0.0513, 0.0462, 0.0482,  ..., 0.0505, 0.0520, 0.0458],\n",
       "         [0.0498, 0.0464, 0.0478,  ..., 0.0493, 0.0496, 0.0464],\n",
       "         [0.0512, 0.0462, 0.0482,  ..., 0.0505, 0.0520, 0.0458],\n",
       "         ...,\n",
       "         [0.0498, 0.0464, 0.0478,  ..., 0.0493, 0.0497, 0.0464],\n",
       "         [0.0499, 0.0464, 0.0478,  ..., 0.0494, 0.0495, 0.0464],\n",
       "         [0.0501, 0.0462, 0.0478,  ..., 0.0495, 0.0506, 0.0462]],\n",
       "\n",
       "        [[0.0515, 0.0463, 0.0484,  ..., 0.0507, 0.0525, 0.0456],\n",
       "         [0.0508, 0.0460, 0.0478,  ..., 0.0501, 0.0511, 0.0460],\n",
       "         [0.0505, 0.0461, 0.0477,  ..., 0.0498, 0.0508, 0.0461],\n",
       "         ...,\n",
       "         [0.0498, 0.0463, 0.0477,  ..., 0.0493, 0.0503, 0.0463],\n",
       "         [0.0509, 0.0459, 0.0479,  ..., 0.0502, 0.0513, 0.0459],\n",
       "         [0.0511, 0.0461, 0.0481,  ..., 0.0504, 0.0517, 0.0459]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0509, 0.0459, 0.0479,  ..., 0.0502, 0.0513, 0.0459],\n",
       "         [0.0504, 0.0461, 0.0477,  ..., 0.0497, 0.0507, 0.0461],\n",
       "         [0.0498, 0.0463, 0.0477,  ..., 0.0493, 0.0504, 0.0463],\n",
       "         ...,\n",
       "         [0.0510, 0.0460, 0.0480,  ..., 0.0503, 0.0515, 0.0459],\n",
       "         [0.0507, 0.0460, 0.0478,  ..., 0.0500, 0.0510, 0.0460],\n",
       "         [0.0517, 0.0464, 0.0485,  ..., 0.0509, 0.0528, 0.0455]],\n",
       "\n",
       "        [[0.0514, 0.0463, 0.0483,  ..., 0.0506, 0.0522, 0.0457],\n",
       "         [0.0508, 0.0460, 0.0478,  ..., 0.0500, 0.0511, 0.0460],\n",
       "         [0.0514, 0.0462, 0.0483,  ..., 0.0505, 0.0522, 0.0457],\n",
       "         ...,\n",
       "         [0.0500, 0.0462, 0.0478,  ..., 0.0495, 0.0505, 0.0462],\n",
       "         [0.0512, 0.0462, 0.0482,  ..., 0.0504, 0.0519, 0.0458],\n",
       "         [0.0507, 0.0460, 0.0478,  ..., 0.0499, 0.0510, 0.0460]],\n",
       "\n",
       "        [[0.0499, 0.0464, 0.0478,  ..., 0.0494, 0.0494, 0.0464],\n",
       "         [0.0498, 0.0463, 0.0477,  ..., 0.0493, 0.0503, 0.0463],\n",
       "         [0.0509, 0.0460, 0.0479,  ..., 0.0502, 0.0514, 0.0459],\n",
       "         ...,\n",
       "         [0.0516, 0.0464, 0.0485,  ..., 0.0509, 0.0527, 0.0455],\n",
       "         [0.0504, 0.0461, 0.0477,  ..., 0.0497, 0.0507, 0.0461],\n",
       "         [0.0513, 0.0462, 0.0482,  ..., 0.0505, 0.0521, 0.0458]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b913287-ba12-4d78-a144-d6656c2293c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 2.9982, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 3.0071, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 2.9932],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 2.9896, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 3.0584, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000,  ..., 2.9981, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [3.0575, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 2.9870, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " - y_target * torch.log(y_pred + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd4c4309-51a5-4299-b5a0-78052379b998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0468, 0.0468, 0.0468,  ..., 0.0484, 0.0505, 0.0487],\n",
       "         [0.0470, 0.0470, 0.0470,  ..., 0.0499, 0.0498, 0.0470],\n",
       "         [0.0477, 0.0470, 0.0470,  ..., 0.0500, 0.0494, 0.0470],\n",
       "         ...,\n",
       "         [0.0468, 0.0468, 0.0468,  ..., 0.0488, 0.0504, 0.0481],\n",
       "         [0.0465, 0.0465, 0.0465,  ..., 0.0474, 0.0507, 0.0501],\n",
       "         [0.0467, 0.0467, 0.0467,  ..., 0.0482, 0.0505, 0.0490]],\n",
       "\n",
       "        [[0.0470, 0.0470, 0.0470,  ..., 0.0498, 0.0500, 0.0470],\n",
       "         [0.0466, 0.0466, 0.0466,  ..., 0.0477, 0.0506, 0.0497],\n",
       "         [0.0469, 0.0469, 0.0469,  ..., 0.0492, 0.0503, 0.0476],\n",
       "         ...,\n",
       "         [0.0467, 0.0467, 0.0467,  ..., 0.0479, 0.0506, 0.0493],\n",
       "         [0.0470, 0.0470, 0.0470,  ..., 0.0496, 0.0502, 0.0470],\n",
       "         [0.0467, 0.0467, 0.0467,  ..., 0.0481, 0.0506, 0.0490]],\n",
       "\n",
       "        [[0.0470, 0.0470, 0.0470,  ..., 0.0498, 0.0501, 0.0470],\n",
       "         [0.0466, 0.0466, 0.0466,  ..., 0.0477, 0.0506, 0.0497],\n",
       "         [0.0469, 0.0469, 0.0469,  ..., 0.0493, 0.0503, 0.0474],\n",
       "         ...,\n",
       "         [0.0475, 0.0470, 0.0470,  ..., 0.0499, 0.0495, 0.0470],\n",
       "         [0.0470, 0.0470, 0.0470,  ..., 0.0498, 0.0499, 0.0470],\n",
       "         [0.0467, 0.0467, 0.0467,  ..., 0.0480, 0.0506, 0.0493]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0470, 0.0470, 0.0470,  ..., 0.0499, 0.0498, 0.0470],\n",
       "         [0.0466, 0.0466, 0.0466,  ..., 0.0475, 0.0507, 0.0500],\n",
       "         [0.0470, 0.0470, 0.0470,  ..., 0.0498, 0.0499, 0.0470],\n",
       "         ...,\n",
       "         [0.0466, 0.0466, 0.0466,  ..., 0.0479, 0.0506, 0.0494],\n",
       "         [0.0470, 0.0470, 0.0470,  ..., 0.0499, 0.0498, 0.0470],\n",
       "         [0.0470, 0.0470, 0.0470,  ..., 0.0496, 0.0502, 0.0470]],\n",
       "\n",
       "        [[0.0468, 0.0468, 0.0468,  ..., 0.0487, 0.0504, 0.0483],\n",
       "         [0.0478, 0.0469, 0.0469,  ..., 0.0501, 0.0494, 0.0469],\n",
       "         [0.0470, 0.0470, 0.0470,  ..., 0.0498, 0.0500, 0.0470],\n",
       "         ...,\n",
       "         [0.0468, 0.0468, 0.0468,  ..., 0.0484, 0.0505, 0.0487],\n",
       "         [0.0470, 0.0470, 0.0470,  ..., 0.0497, 0.0502, 0.0470],\n",
       "         [0.0467, 0.0467, 0.0467,  ..., 0.0480, 0.0506, 0.0493]],\n",
       "\n",
       "        [[0.0469, 0.0469, 0.0469,  ..., 0.0494, 0.0502, 0.0472],\n",
       "         [0.0467, 0.0467, 0.0467,  ..., 0.0482, 0.0505, 0.0490],\n",
       "         [0.0478, 0.0470, 0.0470,  ..., 0.0501, 0.0494, 0.0470],\n",
       "         ...,\n",
       "         [0.0467, 0.0467, 0.0467,  ..., 0.0480, 0.0506, 0.0493],\n",
       "         [0.0465, 0.0465, 0.0465,  ..., 0.0474, 0.0507, 0.0502],\n",
       "         [0.0470, 0.0470, 0.0470,  ..., 0.0499, 0.0498, 0.0470]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3f9cdea0-e862-4ec2-a73f-7473b8e0814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentNeuralProcess(torch.nn.Module):\n",
    "    \"\"\"Basic Latent Neural Process. Takes a decoder and encoder of the form of MLPs, creates a latent variable, and then predicts. Current use case for proteins, but can and should be generalized to continuous data of time series type.\n",
    "    input:\n",
    "        determinstic_encoder: MLP\n",
    "        latent_encoder: MLP\n",
    "        latentLayer_mu: MLP\n",
    "        latentLayer_log_var: MLP\n",
    "        decoder: MLP\n",
    "\n",
    "        for forward method:\n",
    "            context_x, context_y, target_x, target_y (optional)\n",
    "\n",
    "    output:\n",
    "        y_pred: probabilistic predictions of amino acids of size (batch size, target points, number of amino acids)\n",
    "        loss: cross entropy loss of probabilistic predictions. Only given if target_y is specified\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 deterministic_encoder,\n",
    "                 latent_encoder,\n",
    "                 latentLayer_mu,\n",
    "                 latentLayer_log_var,\n",
    "                 decoder,\n",
    "                 **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.deterministic_encoder = deterministic_encoder\n",
    "\n",
    "        self.latent_encoder = latent_encoder\n",
    "        \n",
    "        self.latentLayer_mu = latentLayer_mu\n",
    "        self.latentLayer_log_var = latentLayer_log_var\n",
    "\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, context_x, context_y, target_x, target_y = None):\n",
    "        full_context = torch.concat([context_x, context_y], dim=-1)\n",
    "\n",
    "        deterministic_encoder_output = self.deterministic_encoder(full_context)\n",
    "        deterministic_encoder_output = torch.mean(deterministic_encoder_output, dim=1)\n",
    "\n",
    "        latent_encoder_output = self.latent_encoder(full_context)\n",
    "        latent_encoder_output = torch.mean(latent_encoder_output, dim=1)\n",
    "\n",
    "        z_mu = self.latentLayer_mu(latent_encoder_output)\n",
    "        z_log_var = self.latentLayer_log_var(latent_encoder_output)\n",
    "\n",
    "        z = torch.randn_like(z_log_var) * torch.exp(z_log_var/2) + z_mu\n",
    "\n",
    "        z = z.unsqueeze(dim=1).tile((1, target_x.shape[1],1))\n",
    "\n",
    "        r = deterministic_encoder_output.unsqueeze(dim=1).tile((1, target_x.shape[1],1))\n",
    "\n",
    "        decoder_input = torch.concat([target_x, r, z], dim=-1)\n",
    "        decoder_output = self.decoder(decoder_input)\n",
    "\n",
    "        decoder_output = torch.nn.Softmax(dim=-1)(decoder_output)\n",
    "\n",
    "        if target_y is not None:\n",
    "            loss = self.cross_entropy_loss(decoder_output, target_y)\n",
    "            \n",
    "            X_full = torch.concat([context_x, target_x], dim=1)\n",
    "            Y_full = torch.concat([context_y, target_y], dim=1)\n",
    "            \n",
    "            full_XY = torch.concat([X_full, Y_full], dim=-1)\n",
    "            \n",
    "            target_latent_encoder_output = self.latent_encoder(full_XY)\n",
    "            target_latent_encoder_output = torch.mean(target_latent_encoder_output, dim=1)\n",
    "            \n",
    "            z_mu_target = self.latentLayer_mu(target_latent_encoder_output)\n",
    "            z_log_var_target = self.latentLayer_log_var(target_latent_encoder_output)\n",
    "            \n",
    "            \n",
    "            kl = self.kl_div_calc(z_mu, z_log_var, z_mu_target, z_log_var_target)\n",
    "            return decoder_output, loss + torch.sum(kl)\n",
    "        else:\n",
    "            return decoder_output        \n",
    "        \n",
    "    def cross_entropy_loss(self, output, target_y):\n",
    "        assert output.shape == target_y.shape\n",
    "\n",
    "        cross_entropy_per_site_per_seq = -torch.sum(target_y * torch.log(output+1e-6), dim=-1)\n",
    "        cross_entropy = torch.mean(cross_entropy_per_site_per_seq)\n",
    "        \n",
    "        return cross_entropy\n",
    "\n",
    "    def kl_div_calc(self, z_mu_context, z_log_var_context, z_mu_target, z_log_var_target):\n",
    "        q_context = torch.distributions.Normal(z_mu_context, torch.exp(z_log_var_context/2))\n",
    "        q_target = torch.distributions.Normal(z_mu_target, torch.exp(z_log_var_target/2))\n",
    "        \n",
    "        kl = torch.distributions.kl.kl_divergence(q_context, q_target)\n",
    "        return kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a6a94aeb-219a-4886-965d-bdd99ba84483",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 4\n",
    "d_hidden = 128\n",
    "x_dim = 1\n",
    "y_dim = 21\n",
    "deterministic_encoder = MLP(x_dim+y_dim, 4*[d_hidden])\n",
    "latent_encoder = MLP(x_dim+y_dim, 4*[d_hidden])\n",
    "latentLayer_mu = MLP(d_hidden, [d_hidden,d_hidden,latent_dim])\n",
    "latentLayer_log_var = MLP(d_hidden, [d_hidden,d_hidden,latent_dim])\n",
    "decoder = MLP(d_hidden+latent_dim+x_dim, [d_hidden, d_hidden, d_hidden, y_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2751effb-8e71-418d-af49-bc82cd317284",
   "metadata": {},
   "outputs": [],
   "source": [
    "lnp = LatentNeuralProcess(deterministic_encoder,\n",
    "                          latent_encoder,\n",
    "                          latentLayer_mu,\n",
    "                          latentLayer_log_var,\n",
    "                          decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833635f9-3ab8-4444-ba93-50e51836b073",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 23.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9938, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 24.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9144, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 24.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8974, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 23.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8728, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8001, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8483, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:11, 22.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8326, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8157, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 23.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7702, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:11, 22.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7475, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7939, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 23.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6758, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 23.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6661, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7366, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7926, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:11, 21.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6304, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8282, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 23.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6907, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6922, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7241, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:11, 22.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6806, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6521, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7170, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:11, 22.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6561, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:13, 18.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7170, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:12, 19.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6480, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:11, 21.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7134, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 24.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6558, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:09, 25.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6626, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:09, 25.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6178, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 23.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6325, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6113, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 23.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6305, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6681, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 24.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6868, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 24.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6753, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 24.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5920, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5975, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 23.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6177, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6638, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 24.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6347, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 24.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5577, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 23.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6659, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 23.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5721, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 23.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6899, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 23.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5915, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 23.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6738, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 24.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6005, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 23.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6551, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6359, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 24.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5967, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 24.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6939, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 24.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6713, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5757, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:12, 19.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5810, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:11, 21.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6221, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:11, 20.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5903, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:11, 21.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6396, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5997, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6436, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6079, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 24.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6504, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 24.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5931, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 24.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5845, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 24.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6385, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6610, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 23.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6588, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 23.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5210, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 23.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5937, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 23.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6780, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6656, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:11, 21.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6179, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5776, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6006, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 23.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6226, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6715, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5967, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "246it [00:10, 22.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5405, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "189it [00:08, 24.12it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "EPOCHS=2000\n",
    "full_ANP.train()\n",
    "optim = torch.optim.Adam(lnp.parameters(), lr = 1e-4)\n",
    "writer = SummaryWriter()\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "min_context = int(0.1 * seqs.shape[1])\n",
    "max_context = int(0.9 * seqs.shape[1])\n",
    "len_aa = seqs.shape[1]\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    loader = torch.utils.data.DataLoader(proteins, batch_size=32, shuffle=True)\n",
    "    for i, batch in tqdm(enumerate(loader)):\n",
    "        \n",
    "        global_step+=1\n",
    "        (((x_context, y_context), x_target), y_target) = context_target_splitter(batch, min_context, max_context, len_aa)\n",
    "        adjust_learning_rate(optim, global_step)\n",
    "        \n",
    "        y_pred, loss = lnp(x_context, y_context, x_target, y_target)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        writer.add_scalars('training_loss',{\n",
    "                    'loss':loss,\n",
    "                }, global_step)\n",
    "\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b33bca-a9c5-4d32-9c98-c9843565b789",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
